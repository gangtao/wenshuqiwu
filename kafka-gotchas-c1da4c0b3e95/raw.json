[{
  "tag": "P",
  "text": "Was this article useful to you? I’d love to hear your feedback, so don’t hold back! If you are interested in Kafka or event streaming, or just have any questions, follow me on Twitter.",
  "translation": "这篇文章对您有用吗？ 我希望听到您的反馈，所以请不要退缩！ 如果您对Kafka或事件流感兴趣，或者有任何疑问，请在Twitter上关注我。"
}, {
  "tag": "P",
  "text": "On the balance of it, and in spite of the points above, I wouldn’t say that Kafka is rubbish — quite the opposite. Of course, Kafka isn’t without its flaws. The tooling is sub-par, to put it mildly; the breadth of Kafka’s configuration options is overwhelming, with defaults that are riddled with gotchas, ready to shock the unsuspecting first-time user. But as an event streaming platform, Kafka has shaped the way we now architect and build complex systems. It’s given us choices, and that’s a good thing. Its benefits go beyond the superfluous, and they dwarf any of the niggles that are bound to exist in a technology that has undergone such aggressive adoption.",
  "translation": "总而言之，尽管有上述几点，我也不会说卡夫卡是垃圾。这恰恰相反。 当然，卡夫卡并非没有缺陷。 轻描淡写地说，工具是低于标准的。 卡夫卡（Kafka）配置选项的广度令人难以置信，默认设置中充斥着陷阱，足以震惊那些毫无戒心的初学者。 但是，作为事件流平台，Kafka改变了我们现在架构和构建复杂系统的方式。 它为我们提供了选择，这是一件好事。 它的好处超越了多余的东西，并且使那些已经被如此积极采用的技术束缚住了所有的麻烦。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/30/1*xd_SSivYhyvoWf16VONHDQ.jpeg?q=20",
  "type": "image",
  "file": "1*xd_SSivYhyvoWf16VONHDQ.jpeg"
}, {
  "tag": "H1",
  "text": "Kafka Gotchas",
  "translation": "卡夫卡·格查斯"
}, {
  "tag": "H2",
  "text": "Great, but not Perfect",
  "translation": "很好，但不完美"
}, {
  "tag": "P",
  "text": "I’ve assisted several large clients in building a microservices-style architecture using Kafka as a messaging backbone, having a reasonably good understanding of its abilities and the use cases that really bring them out. But I’m not a Kafka apologist by any stretch; any technology that has gone through such a rapid adoption curve is bound to polarise its audience and rub certain developers up a wrong way, and Kafka is no exception. Like anything else, you need to invest a significant amount of time in getting across Kafka and event streaming in general, before you become fully proficient and can harness its might. And be prepared to face one or two frustrations, to put it mildly, along the way.",
  "translation": "我曾协助数家大型客户使用Kafka作为消息传递主干构建微服务风格的体系结构，并对它的功能和真正使它们发挥作用的用例有相当好的了解。 但是我绝对不是卡夫卡的辩护律师。 经历了如此迅速的采用曲线的任何技术都必定会使其受众两极分化，并以某种错误的方式吸引某些开发人员，Kafka也不例外。 像其他任何事情一样，您需要花费大量时间来全面了解Kafka和事件流，然后才能完全熟练并可以利用其能力。 一路走来，准备面对一两个挫败感。"
}, {
  "tag": "P",
  "text": "I’ve compiled a list of shortcomings that may cause developer frustration, or catch out unsuspecting first-timers. In no particular order:",
  "translation": "我整理了一些缺点，这些缺点可能会导致开发人员感到沮丧，或者赶不上毫无戒心的初学者。 没有特别的顺序："
}, {
  "tag": "H1",
  "text": "Too many tunable knobs",
  "translation": "可调旋钮太多"
}, {
  "tag": "P",
  "text": "The number of configuration parameters in Kafka can be overwhelming, not just for newcomers but also seasoned pros. Possibly with the sole exception of the JVM, I cannot think of another technology that has this many configuration parameters. This isn’t to say that the config options aren’t necessary; but one does wonder how many of those parameters could instead be replaced by ergonomics, much like Java did with G1. So rather than specifying a plethora of individual thresholds and tolerances, let the operator set a performance target, and have the system derive an optimal set of values that best meet this target.",
  "translation": "Kafka中的配置参数数量可能不计其数，不仅对于新手来说，对于经验丰富的专业人士也是如此。 可能是JVM的唯一例外，我想不出具有这么多配置参数的另一种技术。 这并不是说不需要配置选项； 但有人想知道，这些参数中有多少可以被人体工程学代替，就像Java对G1所做的那样。 因此，与其指定过多的单个阈值和公差，不如让操作员设置性能目标，并让系统得出最能满足该目标的最佳值集。"
}, {
  "tag": "H1",
  "text": "Unsafe defaults",
  "translation": "不安全的默认值"
}, {
  "tag": "P",
  "text": "This is my biggest gripe with the config options. Kafka authors make several bold claims around the strength of their ordering and delivery guarantees. You would then be forgiven for assuming that the defaults are sensible, insofar as they ought to favour safety over other competing qualities. Kafka defaults tend to be optimised for performance and will need to be explicitly overridden on the client when safety is a critical objective. Fortunately, setting the properties to warrant safety has only a minor impact on performance — Kafka is still a beast. Remember the first rule of optimisation: Don’t do it. Kafka would have been even better, had their creators given this more thought. Some of the specific examples I’m referring to are:",
  "translation": "这是我对config选项的最大抱怨。 Kafka的作者围绕其订购和交付保证的实力提出了几项大胆的主张。 如果您认为默认值是明智的，那么您将被原谅，因为默认值应该使安全性胜于其他竞争质量。 Kafka默认值通常会针对性能进行优化，并且在安全性很关键的情况下，需要在客户端上明确覆盖默认值。 幸运的是，设置属性以保证安全性对性能仅产生很小的影响-卡夫卡仍然是野兽。 记住优化的第一条规则：不要这样做。 如果卡夫卡的创作者给予更多考虑，卡夫卡本来会更好。 我指的是一些具体示例："
}, {
  "tag": "UL",
  "texts": ["enable.auto.commit — defaults to true, which results in consumers committing offsets every 5 seconds (configured by auto.commit.interval.ms), irrespective of whether the consumer has finished processing the record. Often, this is not what you want, as it may lead to mixed delivery semantics — in the event of consumer failure, some records might be delivered twice, while others might not be delivered at all. This should have been set to false by default, letting the client application dictate the commit point.", "max.in.flight.requests.per.connection — defaults to 5, which may result in messages being published out-of-order if one (or more) of the enqueued messages times out and is retried. This should have been defaulted to 1."],
  "translations": ["enable.auto.commit-默认为true，这导致使用者每5秒提交一次偏移（由auto.commit.interval.ms配置），而不管使用者是否已完成处理记录。 通常，这不是您想要的，因为它可能导致混合的交付语义-在使用者失败的情况下，某些记录可能会交付两次，而另一些记录可能根本无法交付。 默认情况下，应该将其设置为false，让客户端应用程序指定提交点。", "max.in.flight.requests.per.connection —默认为5，如果一个（或多个）排队的消息超时并重试，则可能导致消息乱序发布。 这应该默认为1。"]
}, {
  "tag": "H1",
  "text": "Appalling tooling",
  "translation": "令人震惊的工具"
}, {
  "tag": "P",
  "text": "There is no consistency in the naming of command-line arguments and the simple act of publishing keyed messages requires you to jump through hoops — passing in obscure, undocumented properties. Some native capabilities, such as record headers, aren’t even supported. The usability of the built-in tools is a well-known heartache within the Kafka community. This is a real shame. It’s like buying a Ferrari, only to have it delivered with plastic hub caps. Most Kafka practitioners have long abandoned the out-of-the-box CLI utilities in favour of other open-source tools such as Kafdrop, Kafkacat and third-party commercial offerings like Kafka Tool.",
  "translation": "命令行参数的命名不一致，并且发布键式消息的简单操作要求您跳过圈-传递晦涩的，未记录的属性。 甚至不支持某些本机功能，例如记录标题。 内置工具的可用性是Kafka社区中众所周知的痛点。 这真是可耻。 这就像购买法拉利，只是要用塑料轮毂盖交付。 长期以来，大多数Kafka练习者都放弃了现成的CLI实用程序，而转而使用Kafdrop，Kafkacat等其他开源工具以及Kafka Tool等第三方商业产品。"
}, {
  "tag": "H1",
  "text": "Complicated bootstrapping process",
  "translation": "复杂的引导过程"
}, {
  "tag": "P",
  "text": "The bootstrapping and service discovery process used by clients to establish broker connections is complicated and tends to confuse users. Clients will initially be supplied with a list of broker addresses and ports. A client will then connect to an address at random, discovering the remaining broker nodes, before forming new connections directly to the discovered nodes. This is fairly trivial in a simple, homogeneous network setup where all connections from all clients and peer nodes traverse a single ingress. In a heterogeneous network, there may be several ingress points to segregate broker-to-broker communications, internal clients that live on the same local network, and external clients that might connect over the Internet. The bootstrapping/discovery process needs a special configuration, requiring dedicated listeners and a separate set of advertised listeners that will be presented to the connecting clients.",
  "translation": "客户端用于建立代理连接的引导和服务发现过程很复杂，并且容易使用户感到困惑。 最初将为客户端提供代理地址和端口的列表。 然后，客户端将直接连接到一个地址，发现其余的代理节点，然后再直接建立与所发现节点的新连接。 在简单，同质的网络设置中，这非常简单，其中来自所有客户端和对等节点的所有连接都遍历单个入口。 在异构网络中，可能存在多个入口点以隔离经纪人与经纪人的通信，生活在同一本地网络上的内部客户端以及可能通过Internet连接的外部客户端。 引导/发现过程需要特殊的配置，需要专用的侦听器和一组单独的已通告的侦听器，这些侦听器将呈现给连接的客户端。"
}, {
  "tag": "H1",
  "text": "Shaky client libraries",
  "translation": "摇摇欲坠的客户端库"
}, {
  "tag": "P",
  "text": "The quality/maturity of client libraries in languages other than Java, Python, .NET and C is sub-par. If you are a Java developer, you’ve got it made — that’s where most of the development is concentrated. But Golang and some other communities have struggled in getting access to stable libraries, and while some of these ‘indie’ libraries have been around for several years, the quantity and severity of some of the bugs that I’ve come across in these languages are genuinely concerning.",
  "translation": "使用Java，Python，.NET和C以外的语言编写的客户端库的质量/成熟度均未达到标准。 如果您是Java开发人员，那么就已经做好了–那就是大部分开发工作的集中地。 但是Golang和其他社区在努力获取稳定的库方面一直很努力，尽管其中一些“独立”库已经存在了好几年，但我在这些语言中遇到的一些错误的数量和严重性却是 真正有关。"
}, {
  "tag": "H1",
  "text": "Lack of true multitenancy",
  "translation": "缺乏真正的多租户"
}, {
  "tag": "P",
  "text": "According to Kafka maintainers, it supports multitenancy. The present design is limited to access control lists (ACLs) to segregate topics and maintain quotas, which creates an illusion of isolation for clients, but does not create isolation in the administrative plane. That’s like saying that your fridge supports multitenancy because it lets you store food on different shelves. A true multitenancy solution would provide for multiple logical clusters within a larger, physical cluster. These logical clusters could be administered separately; a misconfiguration of an ACL in one logical cluster, for example, would have no effect on other logical clusters.",
  "translation": "据Kafka的维护者说，它支持多租户。 本设计仅限于访问控制列表（ACL）来隔离主题和维护配额，这给客户端带来了隔离的幻觉，但并未在管理平面中创建隔离。 这就意味着您的冰箱支持多租户，因为它可以让您将食物存放在不同的架子上。 真正的多租户解决方案将在较大的物理群集中提供多个逻辑群集。 这些逻辑集群可以单独管理； 例如，一个逻辑集群中ACL的配置错误对其他逻辑集群没有影响。"
}, {
  "tag": "H1",
  "text": "Lack of geo-awareness",
  "translation": "缺乏地域意识"
}, {
  "tag": "P",
  "text": "Geographical replication isn’t built-in to the brokers, and it is generally accepted that high performance Kafka clusters and ‘stretch’ topologies don’t mix. There is an open-source project — MirrorMaker — which is effectively a pipeline for pumping records from one cluster to another, without preserving any critical metadata (such as offsets). Confluent has its proprietary tool — Replicator — that will preserve metadata, but is a part of the licensed Confluent Enterprise suite.",
  "translation": "地理复制不是内置于代理中的，并且公认的是高性能的Kafka群集和“拉伸”拓扑不会混合使用。 有一个开源项目MirrorMaker，它实际上是一个管道，用于将记录从一个集群泵送到另一个集群，而无需保留任何关键的元数据（例如偏移量）。 Confluent拥有其专有工具Replicator，该工具将保留元数据，但它是许可的Confluent Enterprise套件的一部分。"
}]