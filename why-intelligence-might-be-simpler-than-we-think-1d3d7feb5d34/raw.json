[{
  "tag": "H1",
  "text": "Why Intelligence might be simpler than we think",
  "translation": "为什么情报可能比我们想象的要简单"
}, {
  "tag": "H2",
  "text": "Lessons from the Neocortex",
  "translation": "新大脑皮层的教训"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/30/0*UcQ5ftBwAug2VKth?q=20",
  "caption": "Photo by Paweł Czerwiński on Unsplash",
  "type": "image",
  "file": "0*UcQ5ftBwAug2VKth"
}, {
  "tag": "P",
  "text": "How much information do you need to build a human being and, more specifically, a human brain?",
  "translation": "您需要多少信息来建立一个人，更具体地说是一个人的大脑？"
}, {
  "tag": "P",
  "text": "After all, we are by far the most complex species on the planet. To take it up a notch, some of our brains think that our brains are the most complex structures in the universe!",
  "translation": "毕竟，我们是迄今为止地球上最复杂的物种。 为了解决这个问题，我们的一些大脑认为我们的大脑是宇宙中最复杂的结构！"
}, {
  "tag": "P",
  "text": "Nevertheless, a tomato has more genes than a human being. 7000 more, to be precise.",
  "translation": "然而，番茄比人类具有更多的基因。 准确地说是7000多。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/30/0*sx2PV54xQ-VeiKu-?q=20",
  "caption": "Arguably not the most complex structure in the observable universe. Photo by Immo Wegmann on Unsplash",
  "type": "image",
  "file": "0*sx2PV54xQ-VeiKu-"
}, {
  "tag": "P",
  "text": "Looking at our genes, we have a hard time figuring out where all our complexity is coded for.",
  "translation": "查看我们的基因，我们很难弄清我们所有复杂性的编码位置。"
}, {
  "tag": "P",
  "text": "There are only approximately 20000 genes to begin with, and around half of them are concerned with other things like building hands and feet and vital organs.",
  "translation": "大约只有20000个基因开始，其中大约有一半与其他事物有关，例如建立手脚和重要器官。"
}, {
  "tag": "P",
  "text": "To put it mathematically (considering our genome can be viewed as a code carrying information being processed by something similar to a Turing machine, as I explain in more detail here), our genome only carries 25 million bytes of design information for the brain after lossless compression.",
  "translation": "从数学上讲（考虑到我们的基因组可以看作是携带信息的代码，信息正在由类似于图灵机的东西处理，正如我在这里更详细地解释的那样），我们的基因组经过无损处理后仅携带了2500万字节的大脑设计信息 压缩。"
}, {
  "tag": "P",
  "text": "Gauge that against the 10¹⁵ connections (one quadrillion!) that adults are estimated to have in the neocortex, the most recent part of our brain that only exists in primates and has grown extraordinarily large in homo sapiens. You’ll see that, if we don’t run completely amiss in our understanding of genes, it would be irrational to assume that large portions of our knowledge and abilities are encoded directly in the genes.",
  "translation": "相对于成年人在新皮层中所具有的10 -1连接（一万亿！）的量规，我们大脑的最新部分仅存在于灵长类动物中，并且在智人中异常大。 您会看到，如果我们对基因的理解不完全错位，那么假设我们的大部分知识和能力直接编码在基因中是不合理的。"
}, {
  "tag": "P",
  "text": "The only alternative is that there needs to be a much simpler, more efficient way of defining the blueprint for our brain and for our neocortex.",
  "translation": "唯一的选择是，需要一种更简单，更有效的方法来定义我们的大脑和新皮质的蓝图。"
}, {
  "tag": "P",
  "text": "And with that for building a prototypical intelligent system.",
  "translation": "并以此构建原型智能系统。"
}, {
  "tag": "H2",
  "text": "A unified theory of brain function",
  "translation": "统一的脑功能理论"
}, {
  "tag": "P",
  "text": "In his book On Intelligence, Jeff Hawkins complains that the prevalent picture of the brain is as being composed of highly specialized regions.",
  "translation": "杰夫·霍金斯（Jeff Hawkins）在他的《关于智力的书》中抱怨说，大脑的普遍图片由高度专业化的区域组成。"
}, {
  "tag": "P",
  "text": "He compares this situation with 19th-century biologists examining in ever-increasing detail the large variety of species, without having an eye out for the unifying principles behind life. Until Darwin came along with his theory of evolution, no one understood how to describe the multiplicity of appearances of the natural world in an overarching narrative.",
  "translation": "他将这种情况与19世纪的生物学家越来越详细地研究了各种各样的物种而没有留意生命背后的统一原理进行了比较。 在达尔文提出进化论之前，还没有人知道如何用一种笼统的叙述来描述自然世界的多重表象。"
}, {
  "tag": "P",
  "text": "The brain likewise might look like it’s composed of many different, highly specialized brain regions, but their apparent specialization shouldn’t lead us to conclude that they might not all work based on the same anatomical and algorithmic principles.",
  "translation": "同样，大脑看起来可能由许多不同的高度专业化的大脑区域组成，但是它们明显的专业化不应使我们得出结论，即它们可能并非全部基于相同的解剖学和算法原理而工作。"
}, {
  "tag": "P",
  "text": "In fact, we observe that there is a surprising homogeneity in the anatomy of the neocortex. Neuroplasticity indicates that most brain regions can easily take on tasks previously carried out by other brain regions, showing a certain universality behind their design principles.",
  "translation": "实际上，我们观察到新皮层的解剖结构具有令人惊讶的同质性。 神经可塑性表明，大多数大脑区域可以轻松承担以前由其他大脑区域执行的任务，从而在其设计原理后面显示出一定的通用性。"
}, {
  "tag": "P",
  "text": "In his bestseller The Brain that Changes Itself, Norman Doidge tells impressive stories of patients remapping entire sensory systems to new parts of the brain, like people learning to see with their tongue by mapping visual stimuli recorded with a camera to sensory stimuli straight into their mouth.",
  "translation": "诺曼·道奇（Norman Doidge）在畅销书《改变自身的大脑》中讲述了令人印象深刻的故事，讲述了患者将整个感觉系统重新映射到大脑的新部分的过程，例如人们通过用相机记录的视觉刺激直接将视觉刺激映射到嘴里来学会用舌头观察 。"
}, {
  "tag": "P",
  "text": "Research on stroke patients likewise shows that abilities lost to strokes are routinely relearned by new brain regions, and people born deaf can remap their Broca area (responsible for language processing) to control their hand movements, with which they communicate by sign language, instead of the movement of their mouth, with which they would articulate speech.",
  "translation": "对中风患者的研究同样表明，中风丧失的能力通常是由新的大脑区域重新获得的，而聋哑人可以重新绘制其Broca区域（负责语言处理）以控制其手部动作，并通过手语进行交流，而不是 他们的嘴巴运动，以便与他们说话。"
}, {
  "tag": "P",
  "text": "The brain exerts an incredible capacity and flexibility to learn new things. Most people can learn whichever language they grow up with, or choose to learn a new one later in life, can learn whichever instrument they pick up (admittedly with varying success) and so on.",
  "translation": "大脑发挥不可思议的能力和灵活性来学习新事物。 大多数人可以学习与他们一起成长的任何一种语言，或者选择在以后的生活中学习一种新的语言，也可以学习他们选择的任何一种工具（公认地获得了不同的成功），依此类推。"
}, {
  "tag": "P",
  "text": "The fact of plasticity and flexible learning can be interpreted as pointing, in accord with the sparsity of information in our genes, towards a universal structure underlying both in the biological setup of the neocortex and the learning algorithms with which it operates.",
  "translation": "可塑性和灵活学习的事实可以解释为，根据我们基因中信息的稀疏性，指向了新大脑皮层的生物学设置及其所使用的学习算法所基于的通用结构。"
}, {
  "tag": "H2",
  "text": "The structure of thought",
  "translation": "思想的结构"
}, {
  "tag": "P",
  "text": "It can be difficult to conceptualize thinking itself (as I delved into much more detail in my recent article on the geometry of thought), but there are certain structures and patterns and that run deep through almost every aspect of our cognition.",
  "translation": "很难将概念本身概念化（正如我在最近有关思想几何学的文章中所深入探讨的那样），但是存在某些结构和模式，并且这些结构和模式深深地贯穿了我们认知的各个方面。"
}, {
  "tag": "P",
  "text": "As Ray Kurzweil explains in his book How to Create a Mind, we perceive the world in a hierarchical manner, composed of simple patterns increasing in complexity. According to him, pattern recognition forms the foundation of all thought, from the most primitive patterns up to highly abstract and complex concepts.",
  "translation": "正如雷·库兹韦尔（Ray Kurzweil）在他的《如何创造思维》一书中所解释的那样，我们以一种分层的方式来感知世界，这种方式由复杂程度不断提高的简单模式组成。 他认为，模式识别是所有思想的基础，从最原始的模式到高度抽象和复杂的概念。"
}, {
  "tag": "P",
  "text": "Take language and writing as an example. Small lines build up patterns that we can recognize as letters. Assortments of letters form words, then sentences. Sentences form paragraphs, whole articles. And in the end, out of an assortment of a small number of minimal patterns arranged in a highly specific way, narrative and meaning emerge.",
  "translation": "以语言和写作为例。 细线构成了我们可以识别为字母的模式。 各种字母组成单词，然后是句子。 句子形成段落，整篇文章。 最后，从以高度特定的方式排列的少量最小模式中，出现了叙事和意义。"
}, {
  "tag": "H2",
  "text": "The biology of pattern recognition",
  "translation": "模式识别生物学"
}, {
  "tag": "P",
  "text": "Modern neuroimaging data indicates that the neocortex is composed of a uniform assortment of structures called cortical columns. Each one is built up from around 100 neurons.",
  "translation": "现代神经影像学数据表明，新皮层由称为皮质柱的均匀结构种类组成。 每个人都由大约100个神经元组成。"
}, {
  "tag": "P",
  "text": "Kurzweil proposes that these columns form what he calls minimal pattern recognizers. A conceptual hierarchy is created by connecting layers upon layers of pattern recognizers with each other, each specialized in recognizing a single pattern from the input of one of many different possible sensory modalities (like the eyes, the ears, the nose).",
  "translation": "Kurzweil提出，这些列构成了他所谓的最小模式识别器。 通过将模式识别器的各层彼此连接在一起来创建概念层次，每个模式识别器都专门根据许多可能的感官模式（例如眼睛，耳朵，鼻子）的输入来识别单个模式。"
}, {
  "tag": "P",
  "text": "Building upon basic feature extractions (like detecting edges in visual stimuli or recognizing a tone), these patterns stack up to form more and more intricate patterns.",
  "translation": "在基本特征提取（例如检测视觉刺激中的边缘或识别音调）的基础上，这些模式会叠加起来以形成越来越复杂的模式。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/30/1*igmH6L7atBD5GuW3CmFYCA.jpeg?q=20",
  "caption": "Layers detecting patterns of increasing sophistication in visual data, leading to abstract labels like “elephant” or “penguin”. Credit to Sven Behnke [CC BY-SA 4.0]",
  "type": "image",
  "file": "1*igmH6L7atBD5GuW3CmFYCA.jpeg"
}, {
  "tag": "P",
  "text": "A pattern recognizer is not bound to, say, processing visual or auditory stimuli. It can process all kinds of signals as inputs, generating outputs based on structures contained in the inputs. Learning means wiring up pattern recognizers and learning their weight structure (basically how strong they respond to each other’s input and how much they are interconnected among each other), similar to what is done when learning neural networks.",
  "translation": "模式识别器不限于处理视觉或听觉刺激。 它可以将各种信号作为输入处理，并根据输入中包含的结构生成输出。 学习意味着连接模式识别器并学习其权重结构（基本上是他们对彼此输入的反应有多强，以及它们彼此之间有多少相互联系），类似于学习神经网络时所做的。"
}, {
  "tag": "P",
  "text": "But how can the brain be so homogeneous while being so good at solving many different tasks? The answer might lie in the intersection of neuroscience and computer science.",
  "translation": "但是，大脑在善于解决许多不同任务的同时又如何如此均质呢？ 答案可能在于神经科学和计算机科学的交集。"
}, {
  "tag": "H2",
  "text": "The role of information",
  "translation": "信息的作用"
}, {
  "tag": "P",
  "text": "What does visual, auditory and sensory information have in common? The obvious answer is that it’s all some sort of information.",
  "translation": "视觉，听觉和感觉信息有什么共同点？ 显而易见的答案是，这些都是某种信息。"
}, {
  "tag": "P",
  "text": "While information is frankly a bit tricky to define and gets thrown around way too much in the information age, in the context of information processing in the brain it has a technical meaning. A step towards understanding how this architecture could work so well for us can lie in realizing that the brain can be thought of as an information processing device.",
  "translation": "坦率地说，信息的定义有些棘手，并且在信息时代被抛弃得太多了，但在大脑中进行信息处理的情况下，它具有技术意义。 要了解这种体系结构如何对我们如此有效，就必须迈出一步，即意识到可以将大脑视为一种信息处理设备。"
}, {
  "tag": "P",
  "text": "There is much uniformity in the input to neurons, the underlying currency of neural computation. Whichever signal the brain is processing, it is always composed of spatial and temporal firing patterns of neurons. Every kind of pattern we observe in the outside world is encoded in our sense organs into neural firing patterns, which then, according to Kurzweil, flow upwards and downwards the hierarchy of pattern recognizer until meaning is successfully extracted.",
  "translation": "神经元（神经计算的基础货币）的输入有很多统一性。 大脑正在处理的任何信号，总是由神经元的时空激发模式组成。 我们在外部世界中观察到的每种模式都在我们的感觉器官中编码为神经激发模式，然后根据库兹韦尔的说法，模式识别器的层次结构会向上和向下流动，直到成功提取含义为止。"
}, {
  "tag": "P",
  "text": "The neuroscientific evidence is supported by ideas from computer science. In his book The Master Algorithm, Pedro Domingos proposes that we might find a universal algorithm that would, given the right data, allow us to learn pretty much anything we could think of.",
  "translation": "神经科学证据得到计算机科学思想的支持。 佩德罗·多明戈斯（Pedro Domingos）在他的《大师算法》一书中提出，我们可能会找到一种通用算法，只要有正确的数据，它就能使我们学习到几乎所有我们能想到的东西。"
}, {
  "tag": "P",
  "text": "This universal learning algorithm may even be composed of a mix of already existing learning algorithms (like Bayesian networks, connectionist or symbolist approaches, evolutionary algorithms, support vector machines, etc.).",
  "translation": "这种通用学习算法甚至可以由已经存在的学习算法（例如贝叶斯网络，连接主义或符号主义方法，进化算法，支持向量机等）的混合组成。"
}, {
  "tag": "P",
  "text": "Something akin to this universal algorithm might also be used by the brain, although we are not yet quite sure how the brain learns from an algorithmic perspective. As the most basic example, there’s, of course, Hebbian learning, which has been shown to take place in the brain to some extent. For more sophisticated algorithms, researchers have been trying to find biologically plausible mechanisms for implementing backpropagation in the brain, among many other things.",
  "translation": "尽管我们还不确定如何从算法的角度学习大脑，但是大脑也可能使用类似于该通用算法的东西。 作为最基本的例子，当然有希伯来语学习，这种学习已在某种程度上发生在大脑中。 对于更复杂的算法，研究人员一直在尝试寻找生物学上可行的机制来在大脑中进行反向传播，以及其他许多方面。"
}, {
  "tag": "P",
  "text": "But it is clear that the brain is very good at learning, and needs to do so in a way that we can in principle understand and very probably model on our computers.",
  "translation": "但是很明显，大脑非常擅长学习，并且需要以一种原则上可以理解并且很可能在计算机上建模的方式来做到这一点。"
}, {
  "tag": "H2",
  "text": "Information loss in Neural Networks",
  "translation": "神经网络中的信息丢失"
}, {
  "tag": "P",
  "text": "The trick to recognizing a pattern is to decode it, to parse out the relevant information hidden inside the signal. Learning how the brain does this might be one of the key steps to understanding how intelligence works.",
  "translation": "识别模式的诀窍是对其进行解码，以分析隐藏在信号内部的相关信息。 了解大脑的行为方式可能是了解智力如何运作的关键步骤之一。"
}, {
  "tag": "P",
  "text": "Jeff Hawkins, the author of On Intelligence, complains about our poverty of tools when it comes to studying the role of information in the brain, but there has been increasing progress in understanding information flows in computational architectures.",
  "translation": "On Intelligence的作者Jeff Hawkins抱怨我们在研究信息在大脑中的作用时工具的匮乏，但是在理解计算体系结构中的信息流方面取得了越来越多的进步。"
}, {
  "tag": "P",
  "text": "This summer, I had the great privilege of attending two talks by Israeli neuroscientist Naftali Tishby on his information bottleneck method. With gleaming eyes and an enthusiasm that elated the entire crowd, he explained how information is filtered when deep neural networks extract relevant features from input data (watch his talk at Stanford for an introduction).",
  "translation": "今年夏天，我非常荣幸地参加了以色列神经科学家Naftali Tishby关于其信息瓶颈方法的两次演讲。 他以闪闪发光的眼睛和热情吸引着整个人群，他解释了当深度神经网络从输入数据中提取相关特征时如何过滤信息（观看他在斯坦福大学的演讲以得到介绍）。"
}, {
  "tag": "P",
  "text": "The theory illuminates how information flows in deep neural networks (and gives a nice reason why deep networks tend to work so much better than shallow networks).",
  "translation": "该理论阐明了信息在深度神经网络中的流动方式（并提供了一个很好的理由，说明深度网络比浅层网络的工作性能要好得多）。"
}, {
  "tag": "P",
  "text": "When you learn to recognize a face from pictures with 300x300 pixels, you have 90000 pixels containing information, but a face can, if you know what usually makes up a face, be characterized by much less information (e.g. the relevant features like distance of the eyes, the width of the mouth, the position of the nose, etc.).",
  "translation": "当您从300x300像素的图片中识别出人脸时，您就有90000像素包含信息，但是如果您知道通常由什么构成的人脸，则人脸信息的特征就少得多（例如，相关特征，例如 眼睛，嘴巴的宽度，鼻子的位置等）。"
}, {
  "tag": "P",
  "text": "This idea is used for instance in some deep generative models like Autoencoders (an introduction can be found here), where latent, lower-dimensional representations of the data are learned and then used to generate higher-dimensional, realistic-looking output.",
  "translation": "例如，在一些深层次的生成模型（例如Autoencoders，可以在此处找到介绍）中使用了此思想，在该模型中，学习了数据的潜在低维表示形式，然后将其用于生成高维，逼真的外观输出。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/25/1*Qrz31f3twT_ItaugfYCBgw.png?q=20",
  "caption": "The basic setup of a neural network. Credit to Glosser.ca [CC BY-SA 3.0 (https://creativecommons.org/licenses/by-sa/3.0)]",
  "type": "image",
  "file": "1*Qrz31f3twT_ItaugfYCBgw.png"
}, {
  "tag": "P",
  "text": "Network training methods like stochastic gradient descent allow the network to filter out relevant patterns by throwing out all irrelevant information from the input effectively (like ignoring the background of a photo when classifying the object in the photo, as Ian Goodfellow points out in his book Deep Learning).",
  "translation": "网络训练方法（例如随机梯度下降）使网络可以通过有效地从输入中抛出所有不相关的信息来过滤出相关的模式（例如Ian Goodfellow在他的著作《深层》中指出的那样，在对照片中的物体进行分类时忽略了照片的背景） 学习）。"
}, {
  "tag": "P",
  "text": "Tishby compares it to water flowing from the bottom of a bottle to its top: the bottleneck gets tighter and tighter, and less and less information can flow through. But if the bottleneck is set up well, the water that reaches the top ends up carrying all the necessary information.",
  "translation": "Tishby将其与从瓶子底部流到顶部的水进行比较：瓶颈变得越来越紧密，信息流通的越来越少。 但是，如果瓶颈设置得当，到达顶部的水最终将携带所有必要的信息。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/30/0*Qrs7XFTKyimyZhKr?q=20",
  "caption": "Photo by Jadon Barnes on Unsplash",
  "type": "image",
  "file": "0*Qrs7XFTKyimyZhKr"
}, {
  "tag": "P",
  "text": "I brought this up because I think this information-theoretic perspective can help us understand the idea of the neocortex as composed of pattern recognizers.",
  "translation": "之所以提出这一点，是因为我认为这种信息理论的观点可以帮助我们理解由模式识别器组成的新皮层的概念。"
}, {
  "tag": "P",
  "text": "Pattern recognizers extract patterns from data. These patterns only form a small subset of the input, so in essence, the pattern recognizers of the brain are set up to extract information relevant to our survival from our sense data, and to sort this extracted data into hierarchies of knowledge (I discuss at much more length how this might be structured into conceptual spaces in my article on the Geometry of Thought). These we can then use to bring order into the messy appearance of the world, increasing our chances of survival.",
  "translation": "模式识别器从数据中提取模式。 这些模式仅构成输入的一小部分，因此，实质上，大脑的模式识别器被设置为从我们的感知数据中提取与我们的生存相关的信息，并将此提取的数据分类为知识层次结构（我在 在我关于“思想的几何学”的文章中，如何将其构造成概念空间的篇幅更长）。 然后，我们可以使用这些命令将秩序带入混乱的世界，增加我们生存的机会。"
}, {
  "tag": "P",
  "text": "This is the job of the brain. At its core, it’s an information filtering and ordering device constantly learning useful patterns from data.",
  "translation": "这是大脑的工作。 它的核心是不断地从数据中学习有用模式的信息过滤和排序设备。"
}, {
  "tag": "P",
  "text": "This could well be at the core of what we think of as intelligence, so we might as well learn something from it (as we have been already) when building our own intelligent systems.",
  "translation": "这很可能是我们所认为的智能的核心，因此在构建我们自己的智能系统时，我们不妨从中学习一些东西（就像我们已经学过的一样）。"
}, {
  "tag": "H2",
  "text": "Why intelligence might be simpler than we think",
  "translation": "为什么智慧可能比我们想象的要简单"
}, {
  "tag": "P",
  "text": "I’m no prophet when it comes to the future of AI, and I hope you were taught not to put too much faith in the opinions of strangers on the internet, so take this with a grain of salt.",
  "translation": "关于AI的未来，我不是先知，我希望您被教导不要对互联网上的陌生人的看法过分相信，因此请您放心。"
}, {
  "tag": "P",
  "text": "I admit that there’s much more to information processing and intelligence than simple pattern classification (see for example my article on Ants and the Problems With Neural Networks).",
  "translation": "我承认，信息处理和情报比简单的模式分类要多得多（例如，请参阅我关于“蚂蚁和神经网络问题”的文章）。"
}, {
  "tag": "P",
  "text": "There are many questions to address before we have “solved” intelligence. Inferring causality or general, common sense knowledge structures, as Yann LeCun points out here, is a big issue, and building predictive models of the world into the algorithms (as I go into at length in my article on The Bayesian Brain Hypothesis) is very probably a necessary next step out of many more necessary steps.",
  "translation": "在我们“解决”智能之前，有许多问题需要解决。 正如Yann LeCun在这里指出的那样，推断因果关系或一般常识知识结构是一个大问题，并且在算法中建立世界的预测模型（正如我在有关贝叶斯脑假说的文章中详细介绍的那样） 在许多其他必要步骤中可能是必要的下一步。"
}, {
  "tag": "P",
  "text": "Other open questions, connected to the need for better objective functions, are encountered in reinforcement learning when training robots to carry out tasks intelligently. Being intelligent means solving problems, and one big aspect of this is figuring out the best ways to define objectives and then to achieve these objectives (in the brain, this role is believed to be played by the basal ganglia).",
  "translation": "在训练机器人智能地执行任务时，在强化学习中会遇到其他与更好的目标功能相关的悬而未决的问题。 聪明意味着解决问题，而其中的一个主要方面是找出定义目标然后实现这些目标的最佳方法（在大脑中，这种作用被认为是由基底神经节发挥的作用）。"
}, {
  "tag": "P",
  "text": "So just stacking up pattern recognizers won’t suddenly bring about robots running around reasoning like humans.",
  "translation": "因此，只要堆叠模式识别器，就不会突然带来像人类一样在推理周围运转的机器人。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/30/0*9g5p0cG6AJ5PZvFr?q=20",
  "caption": "Photo by Franck V. on Unsplash",
  "type": "image",
  "file": "0*9g5p0cG6AJ5PZvFr"
}, {
  "tag": "P",
  "text": "I still think the sparsity of information contained in the genetic code supported by the emerging evidence for the simplicity and universality behind the setup of the neocortex and its learning algorithms should let us pause, and take the chances of building highly intelligent machines in the near future more seriously (Kurzweil predicts machines passing the Turing test in 2029 and human-level AI in 2045).",
  "translation": "我仍然认为，由新证据支持的遗传密码中所包含的信息稀疏性，证明了新皮层及其学习算法的简单性和通用性，应该让我们停下来，并抓住机会在不久的将来建造高度智能的机器 更重要的是（库兹韦尔预测机器将在2029年通过图灵测试，在2045年通过人类水平的AI）。"
}, {
  "tag": "P",
  "text": "As P.W. Anderson said in his famous paper about the hierarchy of science, more is different, and more might come out of scaling up the use of simple things if we figured out the right way to scale them up. Some of this has already been apparent in the recent success of deep learning, which is closely tied to scaling up available data and computing power.",
  "translation": "作为P.W. 安德森在他关于科学的层次结构的著名论文中说，更多的不同之处在于，如果我们找到了扩大简单事物的正确方法，那么扩大简单事物的使用可能会产生更多的结果。 在深度学习的最新成功中，其中一些已经很明显，深度学习与扩大可用数据和计算能力紧密相关。"
}, {
  "tag": "P",
  "text": "For me, understanding and building our own intelligence is an absolutely thrilling outlook.",
  "translation": "对我来说，理解和建立自己的智慧绝对是令人振奋的前景。"
}, {
  "tag": "P",
  "text": "But as many people emphasize (this Ted Talk gives a summary), the rise of AI could have large implications for mankind as a whole and should be taken seriously as a problem. And even if we overestimate the problem (because we frankly love thinking about the end of the world a little too much), we should be better safe than sorry.",
  "translation": "但是，正如许多人强调的那样（本特德演讲提供了摘要），人工智能的兴起可能对整个人类产生重大影响，应将其视为一个问题。 即使我们高估了这个问题（因为坦率地说我们爱思考世界末日的想法也太多了），我们应该比后悔更安全。"
}, {
  "tag": "P",
  "text": "Because after all nature came up with intelligence through the blind fancies of evolution. And it looks like we might come up with it as well soon.",
  "translation": "因为毕竟大自然是通过进化的盲目幻想来产生智力的。 看来我们可能很快也会提出。"
}]