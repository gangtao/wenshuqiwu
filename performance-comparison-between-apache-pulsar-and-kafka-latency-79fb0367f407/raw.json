[{
  "tag": "P",
  "text": "Originally published at the Kafkaesque blog on August 29, 2019.",
  "translation": "最初于2019年8月29日发布在Kafkaesque博客上。"
}, {
  "tag": "P",
  "text": "Apache Pulsar, Apache Kafka, and Apache BookKeeper are trademarks of the Apache Software Foundation.",
  "translation": "Apache Pulsar，Apache Kafka和Apache BookKeeper是Apache Software Foundation的商标。"
}, {
  "tag": "P",
  "text": "Want to see what Pulsar is about? Just sign up for the free plan of the Kafkaesque service which is powered by Pulsar to give it a try. It only takes a minute to get started.",
  "translation": "想看看Pulsar是什么？ 只需注册由Pulsar支持的Kafkaesque服务的免费计划即可尝试一下。 只需一分钟即可上手。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*Z525a8_muUDFAt65D-0s1Q.jpeg?q=20",
  "type": "image",
  "file": "1*Z525a8_muUDFAt65D-0s1Q.jpeg"
}, {
  "tag": "H1",
  "text": "Performance Comparison Between Apache Pulsar and Kafka: Latency",
  "translation": "Apache Pulsar和Kafka之间的性能比较：延迟"
}, {
  "tag": "P",
  "text": "Apache Kafka is well known for its high performance. It is able to process a high rate of messages while maintaining low latency. Apache Pulsar is a fast-growing alternative to Kafka. There are reports that suggest Pulsar has better performance characteristics than Kafka, but the raw results are not easy to find. Plus those reports are based on older versions of Pulsar and Kafka, which are both fast-moving projects. So, in a series of posts, we are going to run the latest stable Kafka (2.3.0) and Pulsar (2.4.0) versions through a number of performance tests and publish those results.",
  "translation": "Apache Kafka以其高性能而闻名。 它能够处理高速率的消息，同时保持较低的延迟。 Apache Pulsar是Kafka的快速增长的替代品。 有报告表明，Pulsar具有比Kafka更好的性能特征，但原始结果不容易找到。 此外，这些报告均基于Pulsar和Kafka的较旧版本，它们都是快速发展的项目。 因此，在一系列文章中，我们将通过一系列性能测试来运行最新的稳定的Kafka（2.3.0）和Pulsar（2.4.0）版本，并发布这些结果。"
}, {
  "tag": "P",
  "text": "In this first post, we are going to focus on latency. In future posts, we will look at throughput. Before we dive into the test results, let’s go over the test methodology.",
  "translation": "在第一篇文章中，我们将重点讨论延迟。 在以后的文章中，我们将讨论吞吐量。 在深入测试结果之前，让我们先介绍一下测试方法。"
}, {
  "tag": "H1",
  "text": "Performance Testing Of Messaging systems",
  "translation": "消息系统的性能测试"
}, {
  "tag": "P",
  "text": "Both Kafka and Pulsar provide performance testing tools as part of their packages. While it would be possible to modify the performance tools from either to work with both, we are going to use a third-party benchmark framework from the OpenMessaging Project, a Linux Foundation Collaborative Project. The OpenMessaging Project has a goal of providing vendor-neutral and language-independent standards for messaging and streaming technologies. The project includes a performance testing framework that supports various messaging technologies. All the code used in these tests is in in the OpenMessaging benchmark GitHub repository. The tests are designed to run in public cloud providers. In our case, we are going to running all the tests in Amazon Web Services (AWS) using standard EC2 instances.",
  "translation": "Kafka和Pulsar都将性能测试工具作为其软件包的一部分提供。 虽然可以从任何一个修改性能工具以同时使用它们，但是我们将使用Linux基础协作项目OpenMessaging Project中的第三方基准框架。 OpenMessaging项目的目标是为消息传递和流技术提供与供应商无关的独立于语言的标准。 该项目包括一个性能测试框架，该框架支持各种消息传递技术。 这些测试中使用的所有代码都在OpenMessaging基准测试GitHub存储库中。 这些测试旨在在公共云提供商中运行。 在我们的案例中，我们将使用标准EC2实例在Amazon Web Services（AWS）中运行所有测试。"
}, {
  "tag": "P",
  "text": "We are publishing the full set of outputs from each test run as a series of GitHub gists. So, you are welcome to analyze the data and come up with your own insights. Of course, you could also run the tests yourself and generate new data. You should get similar results since we find the tests are reliable run after run even with different sets of EC2 instances. During our testing, we stood up and tore down the environment multiple times.",
  "translation": "我们将以一系列GitHub要点发布每次测试运行的完整输出。 因此，欢迎您分析数据并提出自己的见解。 当然，您也可以自己运行测试并生成新数据。 您应该得到类似的结果，因为我们发现即使使用不同的EC2实例集，测试也可以可靠地运行。 在测试过程中，我们多次站起来并拆除了环境。"
}, {
  "tag": "P",
  "text": "Although we used the OpenMessaging benchmark tools to run the tests which include a set of workloads, we are going to add some workloads that are inspired by the blog post on the LinkedIn Engineering site titled “ Benchmarking Apache Kafka: 2 Million Writes Per Second (On Three Cheap Machines) “ because we thought it would be interesting for comparison purposes. However, this is quite an old blog post. Today, hardware is better and what we are using is not necessarily cheap, though far from top-of-the-line. So — spoiler alert — both Kafka and Pulsar can handle 2 million writes per second in the blog title without breaking a sweat, which we will see in a future post.",
  "translation": "尽管我们使用OpenMessaging基准测试工具来运行包含一组工作负载的测试，但是我们将添加一些工作负载，这些工作负载的灵感来自LinkedIn Engineering网站上题为“基准化Apache Kafka：每秒200万次写入（ 三台便宜的机器”，因为我们认为进行比较会很有趣。 但是，这是一篇很老的博客文章。 如今，硬件虽然更好，但我们使用的不一定便宜。 因此-扰流板警报-Kafka和Pulsar都可以在博客标题中每秒处理200万次写入，而不会冒汗，我们将在以后的文章中看到。"
}, {
  "tag": "H1",
  "text": "OpenMessaging Benchmark",
  "translation": "OpenMessaging基准测试"
}, {
  "tag": "P",
  "text": "The OpenMessaging benchmark is a framework that is open and extensible. To add a messaging technology to test, you just need to add a Terraform configuration, an Ansible playbook, and an implementation of a Java library that controls the producers and consumers in the test harness. The Terraform configuration currently provided for Kafka and Pulsar are the same, starting the same set of EC2 instances in AWS. Obviously, for comparison purposes, it is important that the test is run on the same hardware configuration. So, the existing benchmark code makes it easy to compare Kafka and Pulsar. As we mentioned, all the code to run these tests is in the OpenMessaging GitHub benchmark repository.",
  "translation": "OpenMessaging基准测试是一个开放且可扩展的框架。 要添加消息技术进行测试，您只需要添加Terraform配置，Ansible手册和Java库的实现，该Java库控制测试工具中的生产者和使用者。 当前为Kafka和Pulsar提供的Terraform配置相同，在AWS中启动相同的EC2实例集。 显然，出于比较目的，在相同的硬件配置上运行测试非常重要。 因此，现有的基准代码可以轻松比较Kafka和Pulsar。 如前所述，所有运行这些测试的代码都在OpenMessaging GitHub基准测试存储库中。"
}, {
  "tag": "P",
  "text": "The tests all begin with a warm-up period before starting the actual measuring phase of the test. The latency tests publish at a constant rate, recording the latency and throughput at regular intervals.",
  "translation": "在开始实际测试阶段之前，所有测试均以预热期开始。 延迟测试以固定的速率发布，并定期记录延迟和吞吐量。"
}, {
  "tag": "P",
  "text": "If you are planning to run these tests yourself, be warned. Running the tests in AWS is not cheap. A significant number of well-powered EC2 instances are needed. This makes sense when doing benchmarks of software. You want to make sure the hardware isn’t the bottleneck, so you oversubscribe the hardware. But this oversubscription comes at a cost (over $5 an hour, $3.8K a month) that will make a mark on your AWS bill if you’re not careful. You don’t want to leave the environment running if you aren’t using it (for example, overnight), and make sure you delete the all resources after running the tests.",
  "translation": "如果您打算自己运行这些测试，请注意。 在AWS中运行测试并不便宜。 需要大量功能强大的EC2实例。 在进行软件基准测试时，这很有意义。 您要确保硬件不是瓶颈，所以您超额订购了硬件。 但是，如果您不小心的话，这种超额订购的成本（每小时5美元，每月3.8万美元）会在您的AWS账单上打上记号。 如果您不使用环境（例如，整夜），则不想让其运行，并确保在运行测试后删除所有资源。"
}, {
  "tag": "H1",
  "text": "Performance Considerations",
  "translation": "性能考量"
}, {
  "tag": "P",
  "text": "Before we dive into the test results, there are a few important concepts we need to cover to put the results in context. First, we need to go over what the test is measuring: latency. Next, we need to go over the durability of the messages, especially when it comes to storing messages to disk. And last we need to understand the different models of message replication used in Kafka and Pulsar.",
  "translation": "在深入测试结果之前，我们需要涵盖一些重要概念以将结果置于上下文中。 首先，我们需要检查测试所测量的内容：延迟。 接下来，我们需要检查消息的持久性，尤其是在将消息存储到磁盘时。 最后，我们需要了解Kafka和Pulsar中使用的消息复制的不同模型。"
}, {
  "tag": "P",
  "text": "There are many similarities between Kafka and Pulsar, but there are some significant differences that can impact performance. To fairly evaluate both systems, you need to understand these differences.",
  "translation": "Kafka和Pulsar之间有很多相似之处，但是有一些明显的差异会影响性能。 为了公平地评估两个系统，您需要了解这些差异。"
}, {
  "tag": "H1",
  "text": "A Note on Latency Tests",
  "translation": "延迟测试的注意事项"
}, {
  "tag": "P",
  "text": "All latency measurements necessarily include the network latency between the application and the messaging system. Assuming all tests are performed in the same network configuration and that network provides consistent latency, then the network latency is a constant that affects all tests equally. When comparing latency measurements, then, it is important the network is held constant when making comparisons.",
  "translation": "所有延迟测量都必须包括应用程序和消息传递系统之间的网络延迟。 假设所有测试均在相同的网络配置中执行，并且该网络提供一致的延迟，则网络延迟是一个常数，会平等地影响所有测试。 因此，在比较等待时间测量值时，进行比较时保持网络恒定很重要。"
}, {
  "tag": "P",
  "text": "We point this out because the latency in these tests differs from those published in the LinkedIn Engineering blog post. Those tests were run on (presumably) a dedicated 1 GB Ethernet network. Our tests are run in the black box network of a public cloud provider on instances that provide “Up to 10 Gigabit” network performance. So, the latency numbers in this test cannot be directly compared with those in that blog post. However, we should be able to compare the latency results between the two messaging systems in our tests, since we are keeping the network configuration constant.",
  "translation": "我们指出这一点是因为这些测试中的延迟与LinkedIn工程博客中发布的延迟不同。 这些测试在（大概）专用的1 GB以太网上运行。 我们的测试在公共云提供商的黑盒网络中运行，并提供“高达10吉比特”网络性能的实例。 因此，此测试中的延迟时间数不能直接与该博客文章中的延迟数进行比较。 但是，由于我们保持网络配置不变，因此我们应该能够在测试中比较两个消息传递系统之间的延迟结果。"
}, {
  "tag": "P",
  "text": "There are two types of latency we are measuring: publishing latency and end-to-end latency.",
  "translation": "我们正在测量两种类型的延迟：发布延迟和端到端延迟。"
}, {
  "tag": "H1",
  "text": "End-to-end Latency",
  "translation": "端到端延迟"
}, {
  "tag": "P",
  "text": "Let’s start by discussing end-to-end latency since it is relatively straightforward. End-to-end latency is simply the time from when the message is sent by the producer to when it received by the consumer. In both the Pulsar and Kafka implementations of the benchmark, the publish timestamp is generated by the API when sending the message. When the message is received by the consumer, a second timestamp is taken. The difference between these two times is the end-to-end latency.",
  "translation": "让我们开始讨论端到端延迟，因为它相对简单。 端到端延迟只是从生产者发送消息到消费者接收消息的时间。 在基准的Pulsar和Kafka实施中，发布时间戳是由API在发送消息时生成的。 当消费者收到消息时，将使用第二个时间戳。 两次之间的差异是端到端延迟。"
}, {
  "tag": "P",
  "text": "Where end-to-end latency gets complicated is with the clocks used to take those timestamp measurements. When measuring end-to-end latency the clocks used for the timestamps must be synchronized. If they are not synchronized, the difference between the clocks will impact your measurements. You end up measuring how much the clocks are different as well as the messaging system latency. Since clocks drift over time, the problem becomes worse in long-running tests.",
  "translation": "端到端延迟变得复杂的地方在于用于进行这些时间戳测量的时钟。 在测量端到端延迟时，必须同步用于时间戳的时钟。 如果它们不同步，则时钟之间的差异将影响您的测量。 您最终需要测量时钟的差异以及消息传递系统的延迟。 由于时钟会随时间漂移，因此在长时间运行的测试中，问题会变得更加严重。"
}, {
  "tag": "P",
  "text": "Ideally, the producer and consumer are on the same server and therefore the timestamps are taken using the same clock, so there is no difference. Unfortunately, the benchmark tests are designed to separate the producer and consumer on to different servers to distribute the load.",
  "translation": "理想情况下，生产者和消费者位于同一台服务器上，因此时间戳使用同一时钟获取，因此没有差异。 不幸的是，基准测试旨在将生产者和使用者分离到不同的服务器上以分配负载。"
}, {
  "tag": "P",
  "text": "The next best option is to synchronize the clocks between the servers as accurately as possible. Luckily, AWS has a free time sync service that, combined with chrony, appears to keep the clocks between EC2 instance in very close sync (within a handful of microseconds of the reference clock). For these tests, we installed chrony on all the client servers and configured them to use the AWS time source.",
  "translation": "第二个最佳选择是尽可能精确地同步服务器之间的时钟。 幸运的是，AWS提供了一个免费的时间同步服务，该服务与chrony相结合，似乎可以使EC2实例之间的时钟保持非常紧密的同步（在参考时钟的几微秒之内）。 对于这些测试，我们在所有客户端服务器上安装了chrony并将其配置为使用AWS时间源。"
}, {
  "tag": "H1",
  "text": "Publishing Latency",
  "translation": "发布延迟"
}, {
  "tag": "P",
  "text": "Publishing latency is the amount of time that passes from when the message is sent until the time an acknowledgment is received from the messaging system. The acknowledgment indicates that the messaging system has persisted the message and will guarantee its delivery. Essentially, the acknowledgment indicates the responsibility for handling the message has been successfully passed from the producing application to the messaging system. Low, consistent publishing latency is good for applications. When the application is ready to hand off the delivery of a message, the messaging system quickly accepts the message, allowing the application to continue working on application-level concerns, such as business logic. This handoff of responsibility for the message is a key feature of any messaging system.",
  "translation": "发布等待时间是从消息发送到接收到消息传递系统的确认为止的时间量。 确认表示消息传递系统已保留该消息并将保证其传递。 实质上，该确认表示处理消息的责任已成功地从生产应用程序传递到消息传递系统。 一致的低发布延迟对应用程序来说很不错。 当应用程序准备好传递消息的传递时，消息传递系统会迅速接受该消息，从而使应用程序可以继续处理应用程序级别的问题，例如业务逻辑。 消息责任的移交是任何消息传递系统的关键功能。"
}, {
  "tag": "P",
  "text": "In the benchmark tests, the messages are sent asynchronously, so the producer doesn’t actually block waiting for the acknowledgment of a message. The call to send the message returns immediately and a callback handles the acknowledgment when it arrives. It may seem that publishing latency is not that important when doing asynchronous sends, but it is. Both the Kafka (max.in.flight.requests.per.connection) and Pulsar (maxPendingMessages) producers have a buffer for holding unacknowledged messages. If this buffer fills up, calls to the send method will start to block (or fail, depending on configuration). So if the messaging system does not quickly acknowledge messages, it can lead to the producing application waiting for the messaging system.",
  "translation": "在基准测试中，消息是异步发送的，因此生产者实际上并不会阻止等待消息的确认。 发送消息的调用立即返回，并且回调在到达时处理确认。 在执行异步发送时，发布延迟似乎并不那么重要，但它却很重要。 Kafka（max.in.flight.requests.per.connection）和Pulsar（maxPendingMessages）生产者都有一个缓冲区，用于保存未确认的消息。 如果此缓冲区已满，则对send方法的调用将开始阻塞（或失败，具体取决于配置）。 因此，如果消息传递系统没有快速确认消息，则可能导致生产应用程序等待消息传递系统。"
}, {
  "tag": "P",
  "text": "In the benchmark tests, the publishing latency is measured from the time when calling the send method until the acknowledgment callback is triggered. These two timestamps are done in the producer, so clock synchronization is not a concern.",
  "translation": "在基准测试中，发布延迟是从调用send方法到触发确认回调之间的时间进行测量的。 这两个时间戳是在生产者中完成的，因此不需要担心时钟同步。"
}, {
  "tag": "H1",
  "text": "Durability and Flushing Messages to Disk",
  "translation": "持久性和刷新消息到磁盘"
}, {
  "tag": "P",
  "text": "Durability in the context of a messaging system means that if parts of the system fail, messages are not lost. To ensure this, messages need to be stored somewhere that will survive a crash of the server running the messaging system software. Both Kafka and Pulsar ultimately write messages to disk as a way to provide durability. However, telling the operating system to write a message to the file system is not sufficient. All POSIX systems cache reads and writes to the file system in memory for improved performance. Writing to the file system only means that the data has been put into the write cache, but it is not necessarily stored safely on the physical disk. Since this cache resides in memory if the server crashes (for example, power loss, kernel panic), data that has been written to the cache but not yet written or flushed to disk will be lost. The operation that forces cached data to be written to the physical disk is called fsync. To guarantee that a message has been stored on disk, the file cache has to be flushed to disk after writing each message by triggering an fsync operation.",
  "translation": "消息系统中的持久性意味着，如果系统的某些部分发生故障，则消息不会丢失。为确保这一点，需要将消息存储在某个位置，该位置将在运行消息传递系统软件的服务器崩溃后幸免。 Kafka和Pulsar最终都将消息写入磁盘，以提供持久性。但是，仅告诉操作系统将消息写入文件系统是不够的。所有POSIX系统都会在内存中缓存对文件系统的读写操作，以提高性能。写入文件系统仅表示已将数据放入写入缓存中，但不一定将其安全地存储在物理磁盘上。由于如果服务器崩溃（例如，断电，内核崩溃），此缓存驻留在内存中，因此已写入缓存但尚未写入或刷新到磁盘的数据将丢失。强制将高速缓存的数据写入物理磁盘的操作称为fsync。为了保证消息已存储在磁盘上，在写入每条消息后，必须通过触发fsync操作将文件缓存刷新到磁盘。"
}, {
  "tag": "P",
  "text": "By default, Kafka does not explicitly flush each message to disk. It leaves the decision when to flush to the operating system. So in the event of a server crash, some undefined amount of message data can be lost. This is the default setting for performance reasons. Writing to the physical disk is slower than writing to the memory cache, so this flushing slows down message processing performance. It is possible to configure Kafka to flush messages regularly (or even for every message), but the Kafka documentation recommends against this for efficiency reasons.",
  "translation": "默认情况下，Kafka不会将每个消息显式刷新到磁盘。 它决定何时刷新到操作系统。 因此，如果服务器崩溃，则可能会丢失一些未定义的消息数据。 由于性能原因，这是默认设置。 写入物理磁盘的速度比写入内存缓存的速度慢，因此这种刷新会降低消息处理性能。 可以将Kafka配置为定期（甚至是每条消息）刷新消息，但是出于效率方面的考虑，Kafka文档建议不要这样做。"
}, {
  "tag": "P",
  "text": "Pulsar, on the other hand, flushes each message to the disk by default. The message is not acknowledged to the producer until it is stored on the physical disk. This provides stronger durability guarantees if the server crashes. It also, as we shall see, is able to provide these durability guarantees while maintaining high performance. It is able to do this because it uses Apache Bookkeeper to store messages, which is a distributed log storage system that has been optimized for this purpose. It is, however, possible to disable this fsync behavior in Pulsar.",
  "translation": "另一方面，默认情况下，Pulsar将每个消息刷新到磁盘。 直到将消息存储在物理磁盘上之前，该消息才被确认给生产者。 如果服务器崩溃，这将提供更强的耐用性保证。 正如我们将看到的，它还能在保持高性能的同时提供这些耐用性保证。 之所以能够做到这一点，是因为它使用Apache Bookkeeper来存储消息，这是为此目的而优化的分布式日志存储系统。 但是，可以在Pulsar中禁用此fsync行为。"
}, {
  "tag": "P",
  "text": "Since the flushing to disk can have an impact on performance, we are going to run the performance tests twice for both Kafka and Pulsar, once with flushing each message to disk enabled and once with it disabled. This will allow for a better apples-to-apples comparison between the two systems.",
  "translation": "由于刷新到磁盘会影响性能，因此我们将对Kafka和Pulsar都运行两次性能测试，一次是将每个消息刷新到磁盘，一次是禁用它。 这样可以在两个系统之间进行更好的比较。"
}, {
  "tag": "H1",
  "text": "Message Replication",
  "translation": "讯息复制"
}, {
  "tag": "P",
  "text": "Both Kafka and Pulsar provide additional message durability by making replicas of each message. That way, even if one of the copies of the message is lost for some reason, there will be other copies available for recovery. Message replication has an effect on performance and is implemented differently on Kafka and Pulsar. We want to make sure we are getting similar replication behavior between Kafka and Pulsar in our tests.",
  "translation": "Kafka和Pulsar都通过复制每条消息来提高消息的持久性。 这样，即使由于某种原因丢失了邮件的一个副本，也将有其他副本可用于恢复。 消息复制会影响性能，并且在Kafka和Pulsar上的实现方式有所不同。 我们要确保在测试中我们在Kafka和Pulsar之间得到类似的复制行为。"
}, {
  "tag": "P",
  "text": "Kafka uses a leader-follower replication model. One of the Kafka brokers is elected the leader for a partition. All messages are initially written to the leader, and the followers read and replicate the messages from the leader. Kafka monitors if each follower is caught up, or “in sync” with the leader. With Kafka, you can control the total number of copies (replication-factor) that are made of a message and the minimum number of replicas that need to be in-sync (min.insync.replicas) before a message is considered successfully stored and acknowledged to the producer. A typical configuration would have Kafka make 3 copies of a message and only acknowledge once at least two (a majority) have been confirmed successfully written. This is the configuration (replication-factor=3, in.sync.replicas=2, acks=all) we will use for all our Kafka tests.",
  "translation": "Kafka使用领导者跟随复制模型。 其中一名卡夫卡经纪人当选为分区负责人。 所有消息最初都会写入领导者，而关注者则从领导者那里读取并复制消息。 Kafka监视每个追随者是否被追赶，或与领导者“同步”。 使用Kafka，您可以控制消息的副本总数（复制因子），以及在消息被成功存储和存储之前，需要同步的最小副本数（min.insync.replicas）。 向制作人承认。 典型的配置是让Kafka制作一条消息的3个副本，并且仅在确认至少两个（大多数）成功写入后才进行确认。 这是我们将用于所有Kafka测试的配置（replication-factor = 3，in.sync.replicas = 2，acks = all）。"
}, {
  "tag": "P",
  "text": "Pulsar uses a quorum-vote replication model. Multiple copies of the message (write quorum) are written in parallel. Once some number of copies have been confirmed stored, then the message is acknowledged (ack quorum). Unlike the leader-follower model which generally writes copies to the same set of leaders and followers for a particular topic partition, Pulsar can spread (or stripe) the copies over a set of storage nodes (ensemble) which can improve the read and write performance. In our tests, we only have 3 storage nodes and want to make 3 copies like with the Kafka configuration, so our settings will not take advantage of striping. Our configuration for Pulsar (ensemble=3, write quorum=3, ack quorum=2) gives similar replication behavior as Kafka: 3 copies of the messages, acknowledge after 2 confirmed.",
  "translation": "Pulsar使用法定投票复制模型。 并行写入消息的多个副本（写仲裁）。 一旦确认已存储一定数量的副本，便确认该消息（确认仲裁）。 与领导者跟随者模型通常将副本写入特定主题分区的同一组领导者和关注者不同，Pulsar可以在一组存储节点（集合）上散布（或条带化）副本，这可以提高读写性能 。 在我们的测试中，我们只有3个存储节点，并且想要像Kafka配置一样制作3个副本，因此我们的设置将不会利用条带化。 我们对Pulsar的配置（合奏= 3，写入仲裁= 3，确认仲裁= 2）提供了与Kafka类似的复制行为：消息的3个副本，在确认2个之后进行确认。"
}, {
  "tag": "P",
  "text": "Now that we have covered off some of these important concepts, let’s move on to the details of the tests.",
  "translation": "现在，我们已经涵盖了其中一些重要概念，让我们继续进行测试的详细信息。"
}, {
  "tag": "H1",
  "text": "Setting Up the Benchmark",
  "translation": "设定基准"
}, {
  "tag": "P",
  "text": "To set up the benchmark tests, we followed the steps documented on the OpenMessaging site. After applying the Terraform configuration, you get the following set of EC2 instances:",
  "translation": "要设置基准测试，我们遵循了OpenMessaging网站上记录的步骤。 应用Terraform配置后，您将获得以下EC2实例集："
}, {
  "tag": "P",
  "text": "The i3.4xlarge instances used for Pulsar/Bookkeeper and the Kafka broker include 2 NVMe SSDs for high disk performance. These are pretty powerful virtual machines, sporting 16 vCPUs, 122 GiB of memory along with their high-performance disks. Having 2 SSDs is ideal for the Pulsar setup since it writes 2 streams of data which can be parallelized on the disks. Kafka also takes advantage of these two SSDs by distributing partitions over both drives.",
  "translation": "用于Pulsar / Bookkeeper和Kafka代理的i3.4xlarge实例包括2个NVMe SSD，以提高磁盘性能。 这些是功能强大的虚拟机，具有16个vCPU，122 GiB内存以及其高性能磁盘。 拥有2个SSD非常适合Pulsar设置，因为它会写入2个可以在磁盘上并行化的数据流。 Kafka还通过在两个驱动器上分配分区来利用这两个SSD。"
}, {
  "tag": "P",
  "text": "The Ansible playbook for both Pulsar and Kafka tunes the performance for low latency using the tuned-adm command (latency-performance profile).",
  "translation": "针对Pulsar和Kafka的Ansible剧本使用tuned-adm命令（延迟性能配置文件）调整了低延迟性能。"
}, {
  "tag": "H1",
  "text": "Workloads",
  "translation": "工作量"
}, {
  "tag": "P",
  "text": "Although the benchmark comes with a set of workloads that we could run right out of the box, we are going to modify them a little bit so that they line up more closely with the benchmark results for Kafka in the LinkedIn Engineering blog. Defining new workloads is easy. You just need to create a YAML file with the updated parameters to use for the test.",
  "translation": "尽管基准测试附带了一些工作负载，我们可以立即使用它们，但是我们将对其进行一些修改，以使其与LinkedIn工程博客中针对Kafka的基准测试结果更加紧密地结合在一起。 定义新的工作负载很容易。 您只需要使用更新后的参数创建一个YAML文件即可用于测试。"
}, {
  "tag": "P",
  "text": "If you look at tests in the LinkedIn blog, you will see that they are all run with 100-byte messages. The reason given “for focusing on small records in these tests is that it is the harder case for a messaging system (generally). “ That makes sense since there is a fixed amount of work to be done for each message regardless of its size, so small messages measure how efficient the system is in processing a message. More efficiency generally leads to higher performance. It also reduces the possibility that the test is being impacted by throughput limits of the network or disk. How well a messaging system performs when handling large messages can be an interesting benchmark, but for now, we are going to focus on small messages.",
  "translation": "如果您查看LinkedIn博客中的测试，则将看到它们均以100字节的消息运行。 给出“在这些测试中专注于小型记录的原因是，这对于消息传递系统而言（通常）更困难。 ”“这是有道理的，因为不管每个消息的大小如何，都有固定数量的工作要做，因此，小的消息将衡量系统在处理消息时的效率。 更高的效率通常会导致更高的性能。 它还降低了测试受到网络或磁盘吞吐量限制的影响的可能性。 消息系统在处理大消息时的性能可能是一个有趣的基准，但是目前，我们将专注于小消息。"
}, {
  "tag": "P",
  "text": "The other change from the stock benchmark workloads is that we are adding a 6-partition test. Six partitions are used extensively in the LinkedIn tests, so we wanted to include that workload in our set.",
  "translation": "股票基准工作负载的另一个变化是，我们添加了6分区测试。 LinkedIn测试中广泛使用了六个分区，因此我们希望将该工作负载包括在我们的集合中。"
}, {
  "tag": "P",
  "text": "You may notice that the LinkedIn blog includes producer-only and consumer-only workloads. All our workloads are going to include both producers and consumers for two reasons. First, as it stands, the benchmark tests do not support standalone producer-only or consumer-only workloads. Second, in the real world, messaging systems will always be serving producers and consumers at the same time. So, both producing and consuming messages during the test gives a more realistic test scenario.",
  "translation": "您可能会注意到，LinkedIn博客包括仅生产者和仅消费者的工作负载。 由于以下两个原因，我们所有的工作量都将包括生产者和消费者。 首先，就目前而言，基准测试不支持独立的仅生产者或仅消费者工作负载。 其次，在现实世界中，消息传递系统将始终同时为生产者和消费者提供服务。 因此，在测试过程中生成和使用消息都会提供更实际的测试方案。"
}, {
  "tag": "P",
  "text": "All that being said, here is the set of workloads we used for these tests:",
  "translation": "话虽如此，这是我们用于这些测试的一组工作负载："
}, {
  "tag": "P",
  "text": "A Kafka consumer group and a Pulsar subscription are similar concepts. They both allow one or more consumers to receive all the messages on a topic. If a topic has multiple consumer groups/subscriptions associated with it, the messaging system is providing multiple copies of each message in the topic, or “fanning out” the message. For each message published into the topic, one message is sent to each consumer group/subscription. If all messages are sent to a single topic that has a single consumer group/subscription, then the producer rate and consumer rate are equal. If, for example, there are two consumer groups/subscriptions, then the consumer rate is double the producer rate. For these tests, we are keeping things simple. There is only one consumer group/subscription, so the producer rate and consumer rate are equal.",
  "translation": "Kafka消费群体和Pulsar订阅是相似的概念。 它们都允许一个或多个消费者接收有关某个主题的所有消息。 如果一个主题具有与之关联的多个消费者组/订阅，则消息传递系统将提供该主题中每个消息的多个副本，或“散开”该消息。 对于发布到主题中的每条消息，都会向每个消费者组/订阅发送一条消息。 如果所有消息都发送到具有单个消费者组/订阅的单个主题，则生产者比率和消费者比率相等。 例如，如果有两个消费者组/订阅，则消费者比率是生产者比率的两倍。 对于这些测试，我们保持简单。 仅有一个消费者组/订阅，因此生产者率和消费者率是相等的。"
}, {
  "tag": "H1",
  "text": "Apache Pulsar Results",
  "translation": "Apache Pulsar结果"
}, {
  "tag": "P",
  "text": "The following sections present the latency results for the Apache Pulsar tests. We first present the results with per-message flushing enabled since this is how Pulsar works out of the box, followed by the results with per-message flushing disabled. For each workload, we include two graphs: one for the 99th percentile publishing latency over the duration of the test, and one for the average end-to-end latency. The graphs are followed by a table that summarizes the latency distribution. The latency measurements reported in the tables are aggregated for the duration of the test. The percentile calculations for end-to-end latency have less precision than the publishing latency since the end-to-end calculations are using the timestamp that is automatically placed in the message header and that timestamp only has ms precision. The publishing latency is calculated using nanosecond precision.",
  "translation": "以下各节介绍了Apache Pulsar测试的延迟结果。 我们首先介绍启用了按消息冲洗的结果，因为这是Pulsar开箱即用的工作方式，其次是禁用了按消息冲洗的结果。 对于每种工作负载，我们都包含两个图形：一个用于测试期间第99个百分点的发布延迟，另一个用于平均端到端延迟。 这些图后面是一个表格，该表格总结了延迟分布。 表中报告的等待时间测量值在测试期间进行汇总。 端到端延迟的百分比计算的精度低于发布延迟，因为端到端计算使用的是自动放置在消息头中的时间戳，并且该时间戳仅具有ms精度。 使用纳秒精度计算发布延迟。"
}, {
  "tag": "P",
  "text": "All tests used a 100-byte message. The produce and consume rates were a constant 50K msgs/s during the 15-minute duration of each test. Only two client servers were used. The version of Apache Pulsar used for the tests was 2.4.0.",
  "translation": "所有测试均使用100字节的消息。 在每个测试的15分钟内，生产速率和消耗速率恒定为50K msgs / s。 仅使用了两个客户端服务器。 用于测试的Apache Pulsar版本为2.4.0。"
}, {
  "tag": "H2",
  "text": "Latency with Flush",
  "translation": "冲洗延迟"
}, {
  "tag": "H2",
  "text": "TEST 1: 1 TOPIC, 1 PARTITION",
  "translation": "测试1：1主题，1分区"
}, {
  "tag": "P",
  "text": "You can get the command output and raw results here.",
  "translation": "您可以在此处获取命令输出和原始结果。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*rYSZwk5PRtFY_oNZdt4x-A.png?q=20",
  "type": "image",
  "file": "1*rYSZwk5PRtFY_oNZdt4x-A.png"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*76nJbQdRkQfOMYVN7ICX2g.png?q=20",
  "type": "image",
  "file": "1*76nJbQdRkQfOMYVN7ICX2g.png"
}, {
  "tag": "FIGURE",
  "type": "code",
  "raw": "https://gist.github.com/cdbartholomew/5dd72b6d9325bf3664aabcc34db2014f/raw/687d9a556d6390f2dbffc7765346a6de8924053f/table.csv",
  "code": "Latency Type,Average,50th,75th,95th,99th,99.9th,99.99th,Maximum\nPublishing (milliseconds),2.969,2.916,3.481,3.911,4.003,4.095,52.958,266.671\nEnd-to-end (milliseconds),9.052,9.0,11.0,13.0,14.0,128.0,213.0,267.0"
}, {
  "tag": "H2",
  "text": "TEST 2: 1 TOPIC, 6 PARTITIONS",
  "translation": "测试2：1个主题，共6个分区"
}, {
  "tag": "P",
  "text": "You can get the command output and raw results here.",
  "translation": "您可以在此处获取命令输出和原始结果。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*UbGhvuFwO7R4N8XRLhEWNw.png?q=20",
  "type": "image",
  "file": "1*UbGhvuFwO7R4N8XRLhEWNw.png"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*wdu7cKrs_JXUzePfQBIFtA.png?q=20",
  "type": "image",
  "file": "1*wdu7cKrs_JXUzePfQBIFtA.png"
}, {
  "tag": "FIGURE",
  "type": "code",
  "raw": "https://gist.github.com/cdbartholomew/29aaca577df99bedd6b00753153c7ab3/raw/504f554223c2556564f96b55bc5c6a0002487132/table.csv",
  "code": "Latency Type,Average,50th,75th,95th,99th,99.9th,99.99th,Maximum\nPublishing (milliseconds),2.800,2.775,3.368,3.848,3.978,4.153,11.224,252.395\nEnd-to-end (milliseconds),8.060,8.0,10.0,13.0,14.0,110.0,199.0,253.0"
}, {
  "tag": "H2",
  "text": "TEST 3: 1 TOPIC, 16 PARTITIONS",
  "translation": "测试3：1个主题，16个分区"
}, {
  "tag": "P",
  "text": "You can get the command output and raw results here.",
  "translation": "您可以在此处获取命令输出和原始结果。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*4N0N_ncnDfXbxYDZq6vRSw.png?q=20",
  "type": "image",
  "file": "1*4N0N_ncnDfXbxYDZq6vRSw.png"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*_kbHRvqzVnZFRDUWSUanbQ.png?q=20",
  "type": "image",
  "file": "1*_kbHRvqzVnZFRDUWSUanbQ.png"
}, {
  "tag": "FIGURE",
  "type": "code",
  "raw": "https://gist.github.com/cdbartholomew/7aa396a2f040a0799dd576dfabc0bb0a/raw/d47b20b1afa91908ea6e9f80f735d5614ac21faa/table.csv",
  "code": "Latency Type,Average,50th,75th,95th,99th,99.9th,99.99th,Maximum\nPublishing (milliseconds),2.723,2.721,3.332,3.843,3.977,4.135,9.712,254.427\nEnd-to-end (milliseconds),3.170,3.0,4.0,4.0,12.0,89.0,178.0,255.0"
}, {
  "tag": "H2",
  "text": "Discussion",
  "translation": "讨论区"
}, {
  "tag": "P",
  "text": "Since partitions are a unit of parallelism in both Pulsar and Kafka, we would expect to see latency reduction as we increase the number of partitions, and this is exactly the result we get. Across the board, as the number of partitions increases both the publishing and the end-to-end latency decreases. There are some outliers in each test, but the maximum latency never exceeds 267 ms. The publishing latency is more tightly bounded than the end-to-end latency. The 99.99th percentile in publishing latency never exceeds 11.6 ms in any of the tests. The effect of extra partitions on latency is most apparent in the end-to-end latency results with 16 partitions. The 16-partition tests record an average latency (3 ms) that is one-third of the 1-partition tests (9 ms).",
  "translation": "由于分区在Pulsar和Kafka中都是并行性的单位，因此随着分区数量的增加，我们期望延迟减少，而这正是我们得到的结果。 总体而言，随着分区数量的增加，发布和端到端的等待时间都减少了。 每个测试中都有一些异常值，但是最大延迟不会超过267 ms。 发布延迟比端到端延迟更严格。 在任何测试中，发布延迟的第99.99个百分点都不会超过11.6 ms。 额外分区对延迟的影响在16个分区的端到端延迟结果中最为明显。 16分区测试记录的平均等待时间（3 ms）是1分区测试（9 ms）的三分之一。"
}, {
  "tag": "P",
  "text": "Pulsar provides consistent publishing latency over time. All the tests run for 15 minutes. As shown in the graphs, the average publishing latency shows very little variation over the duration of the test. The end-to-end latency shows some variability over time, with the average latency increasing by about 2 ms at a regular period of about 90 seconds. Interestingly, this 2-ms periodic bump appears to be constant regardless of the end-to-end latency. For example, the average end-to-end latency is 9 ms for 1 partition and only 3 ms for 16-partitions, but the spike is 2 ms (9 to 11, 3 to 5) in both cases.",
  "translation": "Pulsar随时间提供一致的发布延迟。 所有测试运行15分钟。 如图所示，平均发布延迟在测试期间显示很小的变化。 端到端等待时间显示出随时间的变化，平均等待时间在大约90秒的固定时间内增加了大约2 ms。 有趣的是，无论端到端等待时间如何，该2毫秒的周期性凸起似乎都是恒定的。 例如，一个分区的平均端到端延迟为9毫秒，而16分区的平均端到端延迟仅为3毫秒，但两种情况下的峰值均为2毫秒（9至11、3至5）。"
}, {
  "tag": "H1",
  "text": "Latency without Flush",
  "translation": "没有冲洗的延迟"
}, {
  "tag": "P",
  "text": "The following tests are identical to the previous set, except that per-message flushing to disk is disabled by setting journalSyncData=false in the bookkeeper.conf file and restarting the software (Pulsar broker and Bookkeeper).",
  "translation": "除了通过在bookkeeper.conf文件中设置journalSyncData = false并重新启动软件（Pulsar broker和Bookkeeper）来禁用按消息刷新到磁盘外，以下测试与以前的测试相同。"
}, {
  "tag": "H2",
  "text": "TEST 4: 1 TOPIC, 1 PARTITION",
  "translation": "测试4：1个主题，1个分区"
}, {
  "tag": "P",
  "text": "You can get the command output and raw results here.",
  "translation": "您可以在此处获取命令输出和原始结果。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*tEnR0-Q8hdoamhltzSu0_A.png?q=20",
  "type": "image",
  "file": "1*tEnR0-Q8hdoamhltzSu0_A.png"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*xB-Scz523HazxAtyauVZqw.png?q=20",
  "type": "image",
  "file": "1*xB-Scz523HazxAtyauVZqw.png"
}, {
  "tag": "FIGURE",
  "type": "code",
  "raw": "https://gist.github.com/cdbartholomew/c838d7bbecf7778e0ca961599f86cfdf/raw/f4c5d6018e201190e3862d04ae7121a69398da05/table.csv",
  "code": "Latency Type,Average,50th,75th,95th,99th,99.9th,99.99th,Maximum\nPublishing (milliseconds),2.726,2.694,3.245,3.668,3.783,3.928,4.508,253.055\nEnd-to-end (milliseconds),8.819,9.0,11.0,13.0,14.0,108.0,205.0,253.0"
}, {
  "tag": "H2",
  "text": "TEST 5: 1 TOPIC, 6 PARTITIONS",
  "translation": "测试5：1个主题，共6个分区"
}, {
  "tag": "P",
  "text": "You can get the command output and raw results here.",
  "translation": "您可以在此处获取命令输出和原始结果。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*TTmHAJYgqMIWYfk-VK1yoA.png?q=20",
  "type": "image",
  "file": "1*TTmHAJYgqMIWYfk-VK1yoA.png"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*ooeZGFyTMEf60eWcp0Tbdg.png?q=20",
  "type": "image",
  "file": "1*ooeZGFyTMEf60eWcp0Tbdg.png"
}, {
  "tag": "FIGURE",
  "type": "code",
  "raw": "https://gist.github.com/cdbartholomew/3146fd4915252ce9ae9b1570ceed489b/raw/ce5fa2a55c7e147c844dff5f0fc8b635136db516/table.csv",
  "code": "Latency Type,Average,50th,75th,95th,99th,99.9th,99.99th,Maximum\nPublishing (milliseconds),2.670,2.634,3.211,3.679,3.809,3.952,5.212,239.408\nEnd-to-end (milliseconds),7.930,8.0,10.0,13.0,13.0,116.0,215.0,244.0"
}, {
  "tag": "H2",
  "text": "TEST 6: 1 TOPIC, 16 PARTITIONS",
  "translation": "测试6：1个主题，共16个分区"
}, {
  "tag": "P",
  "text": "You can get the command output and raw results here.",
  "translation": "您可以在此处获取命令输出和原始结果。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*M5Q4AnYWNdu11OCnZgB7_A.png?q=20",
  "type": "image",
  "file": "1*M5Q4AnYWNdu11OCnZgB7_A.png"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*4dobeedttxS4OaXfjIrClA.png?q=20",
  "type": "image",
  "file": "1*4dobeedttxS4OaXfjIrClA.png"
}, {
  "tag": "FIGURE",
  "type": "code",
  "raw": "https://gist.github.com/cdbartholomew/f29282d311f16244fc238ca59712559d/raw/c541965812d62607c2721595f0f1741966fe7492/table.csv",
  "code": "Latency Type,Average,50th,75th,95th,99th,99.9th,99.99th,Maximum\nPublishing (milliseconds),2.677,2.655,3.23,3.691,3.825,3.994,20.883,265.625\nEnd-to-end (milliseconds),3.165,3.0,3.0,4.0,12.0,104.0,190.0,265.0\n"
}, {
  "tag": "H2",
  "text": "Discussion",
  "translation": "讨论区"
}, {
  "tag": "P",
  "text": "As expected, the no-flush results give lower latency, but not very much. For example, the 99th percentile publishing latency with 1 partition when flushing to disk is 4.129 ms but drops to only 3.928 ms when not flushing. In fact, in the 16-partition test, there is little difference between the flush and no-flush cases. The periodic 2-ms spike in end-to-end latency still exists in these tests with the same time interval.",
  "translation": "如预期的那样，不刷新结果提供了较低的延迟，但不是很多。 例如，刷新到磁盘时具有1个分区的第99个百分位数发布延迟为4.129毫秒，但不刷新时降至仅3.928毫秒。 实际上，在16分区测试中，刷新和不刷新情况之间几乎没有差异。 在这些测试中，在相同的时间间隔内，端到端延迟的周期性2毫秒峰值仍然存在。"
}, {
  "tag": "P",
  "text": "Given the durability tradeoff that comes with disabling flushing to disk, it hardly seems worth disabling it from a latency standpoint when using Apache Pulsar.",
  "translation": "考虑到禁用刷新到磁盘所带来的持久性折衷，从使用延迟的角度来看，使用Apache Pulsar禁用它似乎不值得。"
}, {
  "tag": "H1",
  "text": "Apache Kafka Results",
  "translation": "Apache Kafka结果"
}, {
  "tag": "P",
  "text": "Since the default behavior for Kafka is to not flush each message to disk, we are going to start with those results, followed by the results when flushing each message to disk. As with the Pulsar tests, all tests used a 100-byte message and had a message rate of 50K msgs/s. Only two client servers were used. The latency measurements reported in the tables are aggregated for the duration of the test.",
  "translation": "由于Kafka的默认行为是不将每条消息刷新到磁盘，因此我们将从这些结果开始，然后是将每条消息刷新到磁盘时的结果。 与Pulsar测试一样，所有测试都使用100字节的消息，消息速率为50K msgs / s。 仅使用了两个客户端服务器。 表中报告的等待时间测量值在测试期间进行汇总。"
}, {
  "tag": "P",
  "text": "The version of Apache Kafka for these tests was 2.11–2.3.0.",
  "translation": "这些测试的Apache Kafka版本为2.11–2.3.0。"
}, {
  "tag": "H2",
  "text": "Latency with No Flush",
  "translation": "无冲洗延迟"
}, {
  "tag": "H2",
  "text": "TEST 7: 1 TOPIC, 1 PARTITION",
  "translation": "测试7：1个主题，1个分区"
}, {
  "tag": "P",
  "text": "You can get the command output and raw results here.",
  "translation": "您可以在此处获取命令输出和原始结果。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*IT3PVcalC1lKwI0Fra1STA.png?q=20",
  "type": "image",
  "file": "1*IT3PVcalC1lKwI0Fra1STA.png"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*TuijFneUOxMVnWXlWcrRRw.png?q=20",
  "type": "image",
  "file": "1*TuijFneUOxMVnWXlWcrRRw.png"
}, {
  "tag": "FIGURE",
  "type": "code",
  "raw": "https://gist.github.com/cdbartholomew/668c99d65ae4500c85cd75bbd71d6006/raw/166c80bb68a91bde0dd2cdd941e95dbe5191f666/table.csv",
  "code": "Latency Type,Average,50th,75th,95th,99th,99.9th,99.99th,Maximum\nPublishing (milliseconds),2.191,1.733,2.157,2.732,3.15,149.616,201.701,225.463\nEnd-to-end (milliseconds),2.865,2.0,2.0,3.0,7.0,189.0,277.0,341.0"
}, {
  "tag": "H2",
  "text": "TEST 8: 1 TOPIC, 6 PARTITIONS",
  "translation": "测试8：1个主题，共6个分区"
}, {
  "tag": "P",
  "text": "You can get the command output and raw results here.",
  "translation": "您可以在此处获取命令输出和原始结果。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*_tG5n8BAuSs9ZnTg8R--6g.png?q=20",
  "type": "image",
  "file": "1*_tG5n8BAuSs9ZnTg8R--6g.png"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*uKXjJQOciv4_4Au_k4rNVg.png?q=20",
  "type": "image",
  "file": "1*uKXjJQOciv4_4Au_k4rNVg.png"
}, {
  "tag": "FIGURE",
  "type": "code",
  "raw": "https://gist.github.com/cdbartholomew/a1cfe69869e39372cff66baf2dff3aaf/raw/583c16f4c7dc3380d7c1f795d004ae624eb50d4a/table.csv",
  "code": "Latency Type,Average,50th,75th,95th,99th,99.9th,99.99th,Maximum\nPublishing (milliseconds),4.475,3.657,5.814,7.474,8.349,139.389,205.085,213.136\nEnd-to-end (milliseconds),6.508,5.0,7.0,9.0,19.0,189.0,220.0,277.0"
}, {
  "tag": "H2",
  "text": "TEST 9: 1 TOPIC, 16 PARTITIONS",
  "translation": "测试9：1个主题，共16个分区"
}, {
  "tag": "P",
  "text": "You can get the command output and raw results here.",
  "translation": "您可以在此处获取命令输出和原始结果。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*bp01LrGBMKk0UZU5DGZnyw.png?q=20",
  "type": "image",
  "file": "1*bp01LrGBMKk0UZU5DGZnyw.png"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*KyYoso7oNbbk-bSpmCJNGg.png?q=20",
  "type": "image",
  "file": "1*KyYoso7oNbbk-bSpmCJNGg.png"
}, {
  "tag": "FIGURE",
  "type": "code",
  "raw": "https://gist.github.com/cdbartholomew/b33248639484065c50e422be5530c1db/raw/7af186d4354a4be4600b079f0faa7c2a18bcd78b/table.csv",
  "code": "Latency Type,Average,50th,75th,95th,99th,99.9th,99.99th,Maximum\nPublishing (milliseconds),8.479,8.152,8.781,9.635,10.656,169.557,211.642,234.369\nEnd-to-end (milliseconds),11.031,10.0,11.0,12.0,28.0,209.0,259.0,319.0"
}, {
  "tag": "H2",
  "text": "Discussion",
  "translation": "讨论区"
}, {
  "tag": "P",
  "text": "Looking first at the publishing latency with 1 partition, we see that on average Kafka without per-message flushing (2.19 ms) has lower latency than Pulsar whether Pulsar is flushing each message to disk or not ( 2.969 ms flush, 2.72 ms no flush.) However, in the distribution of latency, we see a major difference between Pulsar and Kafka. While Pulsar has tight latency distribution all the way up to the 99.9th percentile (2.916 to 4.095 ms from 50th to 99.9th), Kafka latency spikes up to 149.616 ms at the 99.9th percentile. This is quite a difference. At the 99.99th percentile with 1 partition, Pulsar latency is 52.958 ms and Kafka is nearly 4 times higher at 201.701 ms. And here we are comparing default modes, so Pulsar is flushing each message to disk, while Kafka is not. If you disable flushing to disk for Pulsar, the 99.99th latency drops to just 4.508 ms.",
  "translation": "首先看一下具有1个分区的发布延迟，我们发现，无论是否将每个消息都刷新到磁盘上，不进行每条消息刷新的Kafka平均而言（2.19 ms）的延迟要低于Pulsar（2.969 ms刷新，2.72 ms不刷新）。 ）但是，在延迟的分布上，我们看到了Pulsar和Kafka之间的主要差异。 尽管Pulsar的延迟分布一直很紧密，一直到第99.9个百分点（从第50个到99.9个百分点从2.916到4.095 ms），但Kafka延迟在第99.9个百分点达到149.616 ms。 这是完全不同的。 在具有1个分区的第99.99个百分点处，Pulsar延迟为52.958毫秒，而Kafka则为201.701毫秒，几乎高出4倍。 在这里，我们正在比较默认模式，因此Pulsar会将每个消息刷新到磁盘，而Kafka则不会。 如果您禁用了对Pulsar的磁盘刷新功能，则第99.99个延迟将降至4.508 ms。"
}, {
  "tag": "P",
  "text": "The reason for the large number of publishing latency outliers in Kafka seems pretty obvious when looking at the graph of 99th percentile publishing latency over time. Kafka shows periodic spikes where publishing latency jumps from single digits to over 100 ms. The effect is diminished as the number of partitions is increased, but is still present. Compare this to Pulsar where the 99th percentile publishing latency is essentially a straight line for the entire duration of the test.",
  "translation": "当查看时间上第99个百分位发布延迟的图表时，卡夫卡中大量发布延迟异常值的原因似乎很明显。 Kafka显示了周期性的峰值，其中发布延迟从个位数跃升到100毫秒以上。 随着分区数量的增加，效果会减弱，但仍然存在。 将其与Pulsar进行比较，在整个测试期间，第99个百分点的发布延迟基本上是一条直线。"
}, {
  "tag": "P",
  "text": "Another interesting difference between Pulsar and Kafka is that increasing the number of partitions lowers the publishing latency for Pulsar, but has the opposite effect for Kafka. Although the average publishing latency for Kafka is lower than Pulsar for the 1-partition test, Pulsar is lower for the 6- and 16-partition tests. For the 16-partition test, Pulsar gives under 3 ms of average publishing latency, while Kafka has nearly 8.5 ms.",
  "translation": "Pulsar和Kafka之间的另一个有趣的区别是，增加分区数可以降低Pulsar的发布延迟，但对Kafka却具有相反的作用。 尽管对于1分区测试，Kafka的平均发布延迟低于Pulsar，但对于6分区和16分区测试，Pulsar较低。 对于16个分区的测试，Pulsar给出的平均发布延迟少于3 ms，而Kafka的发布延迟接近8.5 ms。"
}, {
  "tag": "P",
  "text": "Looking at the average end-to-end latency, Kafka beats Pulsar at the lowest partition count, but as with the publishing latency, end-to-end latency increases with partition count, so that at 16-partitions, Kafka has an average end-to-end latency of 11 ms, while Pulsar is approaching 3 ms. With end-to-end latency over time, we saw a periodic 2 ms spike with Pulsar. With Kafka, we similarly see spikes, but they are more frequent and typically higher, often spiking over 5 ms.",
  "translation": "从平均端到端延迟来看，Kafka在最低的分区数量上击败了Pulsar，但是与发布延迟一样，端到端延迟随着分区数量的增加而增加，因此在16个分区上，Kafka的平均端 -端延迟为11 ms，而Pulsar接近3 ms。 随着时间的流逝，我们看到了Pulsar周期性的2 ms尖峰。 使用Kafka，我们同样会看到尖峰，但它们更频繁且通常更高，通常超过5 ms。"
}, {
  "tag": "H1",
  "text": "Latency with Flush",
  "translation": "冲洗延迟"
}, {
  "tag": "P",
  "text": "These tests are identical to the previous set, except that per-message flushing (fsync) is enabled. This was configured (flush.messages=1, flush.ms=0) for all topics used in the test.",
  "translation": "这些测试与以前的测试相同，除了启用了按消息刷新（fsync）。 已针对测试中使用的所有主题进行了配置（flush.messages = 1，flush.ms = 0）。"
}, {
  "tag": "H2",
  "text": "TEST 10: 1 TOPIC, 1 PARTITION",
  "translation": "测试10：1个主题，1个分区"
}, {
  "tag": "P",
  "text": "You can get the command output and raw results here.",
  "translation": "您可以在此处获取命令输出和原始结果。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*-uxPGrynqrElp0US5vsjGw.png?q=20",
  "type": "image",
  "file": "1*-uxPGrynqrElp0US5vsjGw.png"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*ym8cHJYFKI8VlhQV7a4SBQ.png?q=20",
  "type": "image",
  "file": "1*ym8cHJYFKI8VlhQV7a4SBQ.png"
}, {
  "tag": "FIGURE",
  "type": "code",
  "raw": "https://gist.github.com/cdbartholomew/cc4e53158a067e6255d2c525b5492c47/raw/42e1ad220086d09118ce00723d4fb79e12ce9b7c/table.csv",
  "code": "Latency Type,Average,50th,75th,95th,99th,99.9th,99.99th,Maximum\nPublishing (milliseconds),6.652,6.747,7.277,8.032,8.641,22.416,194.108,219.741\nEnd-to-end (milliseconds),7.129,7.0,7.0,8.0,9.0,170.0,210.0,243.0"
}, {
  "tag": "H2",
  "text": "TEST 11: 1 TOPIC, 6 PARTITIONS",
  "translation": "测试11：1个主题，共6个分区"
}, {
  "tag": "P",
  "text": "You can get the command output and raw results here.",
  "translation": "您可以在此处获取命令输出和原始结果。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*o0MEBz6rBw30UXJDQQfKTw.png?q=20",
  "type": "image",
  "file": "1*o0MEBz6rBw30UXJDQQfKTw.png"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*UKhZjcId5uFUMychZ3nX5g.png?q=20",
  "type": "image",
  "file": "1*UKhZjcId5uFUMychZ3nX5g.png"
}, {
  "tag": "FIGURE",
  "type": "code",
  "raw": "https://gist.github.com/cdbartholomew/6d073be477a70e6ff62b1fce6464ef02/raw/678b7cf09565187d6fe75de26631da47c0b1b85d/table.csv",
  "code": "Latency Type,Average,50th,75th,95th,99th,99.9th,99.99th,Maximum\nPublishing (milliseconds),11.125,10.823,11.33,12.081,13.517,132.025,212.062,225.853\nEnd-to-end (milliseconds),13.857,13.0,13.0,15.0,32.0,208.0,239.0,287.0\n"
}, {
  "tag": "H2",
  "text": "TEST 12: 1 TOPIC, 16 PARTITIONS",
  "translation": "测试12：1个主题，共16个分区"
}, {
  "tag": "P",
  "text": "You can get the command output and raw results here.",
  "translation": "您可以在此处获取命令输出和原始结果。"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*jrEf06EV6Iy81DgHMNvtqg.png?q=20",
  "type": "image",
  "file": "1*jrEf06EV6Iy81DgHMNvtqg.png"
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*2WCCTK5N6SNJ9KaESdDmYQ.png?q=20",
  "type": "image",
  "file": "1*2WCCTK5N6SNJ9KaESdDmYQ.png"
}, {
  "tag": "FIGURE",
  "type": "code",
  "raw": "https://gist.github.com/cdbartholomew/60c36c79ddd64cf763419543abedde4e/raw/d8d5bc81f3853c7bbf076b73fd885b1deec7dddc/table.csv",
  "code": "Latency Type,Average,50th,75th,95th,99th,99.9th,99.99th,Maximum\nPublishing (milliseconds),18.454,17.935,19.815,22.075,23.404,123.801,222.137,290.615\nEnd-to-end (milliseconds),21.119,20.0,22.0,25.0,33.0,199.0,259.0,334.0\n"
}, {
  "tag": "H2",
  "text": "Discussion",
  "translation": "讨论区"
}, {
  "tag": "P",
  "text": "This set of tests are an apples-to-apples comparison to Pulsar’s default behavior of flushing each message to disk. In this comparison, Pulsar is clearly better. In the 1-partition test where Kafka had an advantage over Pulsar when it wasn’t flushing to disk, when both systems are flushing to disk, Pulsar’s average latency is 2.969 ms while Kafka’s is more than double at 6.652 ms. Because adding partitions still increases latency for Kafka in these tests, the disparity grows even greater at 16-partitions where Pulsar is giving 2.72 ms of latency and Kafka is clocking in at 18.454 ms, which is 6 times higher.",
  "translation": "这组测试是对Pulsar将每条消息刷新到磁盘的默认行为的逐个比较。 在这种比较中，脉冲星显然更好。 在1分区测试中，当卡夫卡没有冲刷到磁盘时，卡夫卡比普尔萨尔有优势。当两个系统都冲刷到磁盘时，卡夫卡的平均延迟为2.969毫秒，而卡夫卡的平均延迟为6.652毫秒，是原来的两倍多。 由于在这些测试中添加分区仍然会增加Kafka的延迟，因此，在16个分区中，Pulsar的延迟为2.72 ms，而Kafka的时钟为18.454 ms，这是6倍，差距甚至更大。"
}, {
  "tag": "P",
  "text": "The large publishing latency spikes still remain when Kafka is configured to flush each message to disk, but happen less often.",
  "translation": "当Kafka配置为将每条消息刷新到磁盘时，仍然会出现较大的发布延迟峰值，但是这种情况很少发生。"
}, {
  "tag": "P",
  "text": "For average end-to-latency, not surprisingly flushing to disk increases the latency for Kafka across the board. Kafka actually has an advantage in the 1-partition case ( 7.129 vs 9.052 ms), but Pulsar is clearly better in the 6- and 16-partitions cases. Looking at the end-to-end latency over time with Kafka, there are still periodic spikes as high as 5 ms.",
  "translation": "对于平均的端到端延迟，毫不奇怪地刷新到磁盘会增加整个Kafka的延迟。 实际上，Kafka在1分区的情况下具有优势（7.129 vs 9.052 ms），但在6分区和16分区的情况下Pulsar显然更好。 从Kafka的时间来看端到端延迟，仍然存在高达5 ms的周期性尖峰。"
}, {
  "tag": "H1",
  "text": "Wrapping Up",
  "translation": "包起来"
}, {
  "tag": "P",
  "text": "Based on this set of results, we can draw the following conclusions:",
  "translation": "基于这组结果，我们可以得出以下结论："
}, {
  "tag": "UL",
  "texts": ["Pulsar gives more predictable latency over time. The graphs of latency over time are smoother with Pulsar than Kafka. This comparison chart shows one case where Kafka latency is actually lower than Pulsar, but the Pulsar plot is less variable:"],
  "translations": ["随着时间的推移，Pulsar可以提供更多可预测的延迟。 与Kafka相比，Pulsar随时间推移的潜伏期图更加平滑。 此比较图显示了一种情况，其中Kafka延迟实际上低于Pulsar，但Pulsar图的变化较小："]
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*vgIym4oJJNqZnLOBkB8qgg.png?q=20",
  "caption": "Average end-to-end latency, 6-partition, no flushing",
  "type": "image",
  "file": "1*vgIym4oJJNqZnLOBkB8qgg.png"
}, {
  "tag": "UL",
  "texts": ["Pulsar has more tightly bounded latency. Most of the Kafka tests show elevated latency at the 99.9th percentile. In the few cases where Pulsar shows elevated latency, it occurs at the 99.99th percentile. This comparison chart, clearly shows just how bounded Pulsar latency is compared to Kafka:"],
  "translations": ["脉冲星具有更严格的延迟。 大多数Kafka测试显示，延迟时间提高了99.9个百分点。 在极少数情况下，Pulsar的延迟增加，发生在第99.99个百分点。 该比较表清楚地显示了与Kafka相比，有限的Pulsar延迟如何："]
}, {
  "tag": "FIGURE",
  "image": "https://miro.medium.com/max/60/1*kY6bzNpOIpYdYipV5ulX_A.png?q=20",
  "caption": "99th percentile publishing latency, 6-partition, flushing",
  "type": "image",
  "file": "1*kY6bzNpOIpYdYipV5ulX_A.png"
}, {
  "tag": "UL",
  "texts": ["Increasing the partition count for a Pulsar topic lowers latency when using a single producer and consumer. Increasing the partition count for a Kafka topic increases latency for a single producer and consumer.", "Given a need for the highest message durability, Pulsar provides lower latency than Kafka.", "Disabling flushing of messages to disk with Pulsar provides small latency gains and is not warranted given the durability tradeoff."],
  "translations": ["当使用单个生产者和使用者时，增加Pulsar主题的分区数可减少延迟。 增加Kafka主题的分区数量会增加单个生产者和消费者的延迟。", "考虑到最高消息持久性的需求，Pulsar提供的延迟比Kafka低。", "使用Pulsar禁用将消息刷新到磁盘可带来较小的延迟增加，并且考虑到持久性，因此不保证这样做。"]
}, {
  "tag": "P",
  "text": "For latency-sensitive workloads, Pulsar is the overall winner. It is able to provide consistent, low latency as well as strong durability guarantees. Of course, not all workloads are latency-sensitive. Some may be willing to tradeoff latency for higher throughput. In a future post, we will be doing a similar comparison of the throughput performance between Apache Kafka and Apache Pulsar.",
  "translation": "对于延迟敏感的工作负载，Pulsar是整体赢家。 它能够提供一致的低延迟以及强大的耐用性保证。 当然，并非所有工作负载都对延迟敏感。 一些人可能愿意权衡延迟以获得更高的吞吐量。 在以后的文章中，我们将对Apache Kafka和Apache Pulsar之间的吞吐量性能进行类似的比较。"
}, {
  "tag": "P",
  "text": "If you found this post useful, please let us know in the comments.",
  "translation": "如果您发现此帖子有用，请在评论中告知我们。"
}, {
  "tag": "PRE",
  "text": "(本文翻译自Chris Bartholomew的文章《Performance Comparison Between Apache Pulsar and Kafka: Latency》，参考：https://medium.com/swlh/performance-comparison-between-apache-pulsar-and-kafka-latency-79fb0367f407)",
  "translation": "（本文翻译自克里斯·巴塞洛缪的文章《 Apache Pulsar和Kafka之间的性能比较：延迟》，参考：https：//medium.com/swlh/performance-comparison-between-apache-pulsar-and-kafka-latency-79fb0367f407）"
}]